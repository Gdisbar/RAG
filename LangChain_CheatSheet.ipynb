{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "75ef850e031f41d2b6b206f520216b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ab1362548de445caa3aa4c63c886ff1",
              "IPY_MODEL_9cc0c59087f646139aefe56c6ec0e908",
              "IPY_MODEL_89bd9806bfb24b98a62baefb7a9b4aab"
            ],
            "layout": "IPY_MODEL_9f2ae991f2cf426a9488b223cc5f8ea3"
          }
        },
        "0ab1362548de445caa3aa4c63c886ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dec30cbfa5a443c8b464e0307297c18",
            "placeholder": "​",
            "style": "IPY_MODEL_7483faa776394bafa7ac359b968a7cd1",
            "value": "modules.json: 100%"
          }
        },
        "9cc0c59087f646139aefe56c6ec0e908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24de4a76ee114719867845982281489f",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67d9d361a0924d208dea38af0e4ce441",
            "value": 349
          }
        },
        "89bd9806bfb24b98a62baefb7a9b4aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_477537b95bea4ecfaab7251cb484f2aa",
            "placeholder": "​",
            "style": "IPY_MODEL_ec54dcbe5725493ab5276c5d25f19616",
            "value": " 349/349 [00:00&lt;00:00, 31.9kB/s]"
          }
        },
        "9f2ae991f2cf426a9488b223cc5f8ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dec30cbfa5a443c8b464e0307297c18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7483faa776394bafa7ac359b968a7cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24de4a76ee114719867845982281489f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67d9d361a0924d208dea38af0e4ce441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "477537b95bea4ecfaab7251cb484f2aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec54dcbe5725493ab5276c5d25f19616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c98ed31c8be2449a881afcb2d4f98b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30651ed96e134f4f8c2af67f5cf5e24c",
              "IPY_MODEL_c5286f46798c4fd7ae8c85779bec84fa",
              "IPY_MODEL_a0bc7e4d19b040489dbfc465ad023fa1"
            ],
            "layout": "IPY_MODEL_bc7b12776b8b4bb39e0915ac5d0ab1c8"
          }
        },
        "30651ed96e134f4f8c2af67f5cf5e24c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7906d74c2d645df8fc18418accd74ff",
            "placeholder": "​",
            "style": "IPY_MODEL_019b5fb2c7f54a699c0aadc069e045e4",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "c5286f46798c4fd7ae8c85779bec84fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a5d697d31d34188acdc7c0e4377cd4a",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50a63e49c5554be6aade00e73e9bf292",
            "value": 116
          }
        },
        "a0bc7e4d19b040489dbfc465ad023fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28f158c7e74146f28bb00c2130e05089",
            "placeholder": "​",
            "style": "IPY_MODEL_a1ad5d3666eb437e89b97b514c2f024d",
            "value": " 116/116 [00:00&lt;00:00, 8.99kB/s]"
          }
        },
        "bc7b12776b8b4bb39e0915ac5d0ab1c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7906d74c2d645df8fc18418accd74ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019b5fb2c7f54a699c0aadc069e045e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a5d697d31d34188acdc7c0e4377cd4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50a63e49c5554be6aade00e73e9bf292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28f158c7e74146f28bb00c2130e05089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1ad5d3666eb437e89b97b514c2f024d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "570af803527f4668bf87aa139cfac5d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79f51841a6034349aeec38f76e56083c",
              "IPY_MODEL_a87004e84786459ca36ef10a04d1cac1",
              "IPY_MODEL_776e155cf73a4ad4ad77a68253ac9b9c"
            ],
            "layout": "IPY_MODEL_01aaa1489a244a78865dff9e598def6a"
          }
        },
        "79f51841a6034349aeec38f76e56083c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92ff24c903ff4644936fb146eccf9ca6",
            "placeholder": "​",
            "style": "IPY_MODEL_1613229335be455cb601bf50928f14da",
            "value": "README.md: 100%"
          }
        },
        "a87004e84786459ca36ef10a04d1cac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12524676cb1c4a99bd79aed9243ccb5e",
            "max": 10415,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22723561d1ac403db3210521318e77ff",
            "value": 10415
          }
        },
        "776e155cf73a4ad4ad77a68253ac9b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_401918f9301e461797bf88db930a7645",
            "placeholder": "​",
            "style": "IPY_MODEL_3391580365bd4229ba5328c932ead249",
            "value": " 10.4k/10.4k [00:00&lt;00:00, 907kB/s]"
          }
        },
        "01aaa1489a244a78865dff9e598def6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92ff24c903ff4644936fb146eccf9ca6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1613229335be455cb601bf50928f14da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12524676cb1c4a99bd79aed9243ccb5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22723561d1ac403db3210521318e77ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "401918f9301e461797bf88db930a7645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3391580365bd4229ba5328c932ead249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99c2fd71fe5c42d0836d6d0c3e23fe39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_768744466f0d41469c3f558e122bbe5e",
              "IPY_MODEL_fc9eb87075c3448b8ff5baa7cd2ab2d9",
              "IPY_MODEL_227c2ad48cab492281a5e87687533e96"
            ],
            "layout": "IPY_MODEL_31c5a3126a9240d98f91cf0e201264a9"
          }
        },
        "768744466f0d41469c3f558e122bbe5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c323afabcab446391eb3267f6e29e48",
            "placeholder": "​",
            "style": "IPY_MODEL_8290d25706694dfdb4450c5f4a7d6bc8",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "fc9eb87075c3448b8ff5baa7cd2ab2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9deda9b486e24148845e0a9a24a2dd0d",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5da819e637d498db9ff62fd2085d1af",
            "value": 53
          }
        },
        "227c2ad48cab492281a5e87687533e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ca1f65ebcac46c7a3a907f1331dc046",
            "placeholder": "​",
            "style": "IPY_MODEL_8fd914e08ad94b3f846a546ebe9db4cf",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.91kB/s]"
          }
        },
        "31c5a3126a9240d98f91cf0e201264a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c323afabcab446391eb3267f6e29e48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8290d25706694dfdb4450c5f4a7d6bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9deda9b486e24148845e0a9a24a2dd0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5da819e637d498db9ff62fd2085d1af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ca1f65ebcac46c7a3a907f1331dc046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fd914e08ad94b3f846a546ebe9db4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0c490b11f3b48768196ed17a9f5042a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6d7f10f4565477fab36fc3b1588bd77",
              "IPY_MODEL_123590c900284da788289af9de84381b",
              "IPY_MODEL_5044e1086ebc4908921b2890e2f3fc91"
            ],
            "layout": "IPY_MODEL_46bcdc2f9a8c4410863ff455fd9bb27e"
          }
        },
        "f6d7f10f4565477fab36fc3b1588bd77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb4ba15864cf420b8cd0095cc463649b",
            "placeholder": "​",
            "style": "IPY_MODEL_8a14b3ba3a074b5184dfda6e60213030",
            "value": "config.json: 100%"
          }
        },
        "123590c900284da788289af9de84381b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b98954613eba452ba76207f98b7ac94c",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f934c9d227942aab0d6f2a96ffff385",
            "value": 571
          }
        },
        "5044e1086ebc4908921b2890e2f3fc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82012982f33746229e844adb1ace374e",
            "placeholder": "​",
            "style": "IPY_MODEL_09b1091d08664cafae3772320f0e629d",
            "value": " 571/571 [00:00&lt;00:00, 47.4kB/s]"
          }
        },
        "46bcdc2f9a8c4410863ff455fd9bb27e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb4ba15864cf420b8cd0095cc463649b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a14b3ba3a074b5184dfda6e60213030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b98954613eba452ba76207f98b7ac94c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f934c9d227942aab0d6f2a96ffff385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82012982f33746229e844adb1ace374e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b1091d08664cafae3772320f0e629d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1153f387b48440ceaced340f8d52c692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a32e2f93a5894a54a816055564b389c9",
              "IPY_MODEL_93f75d1fc6ba455e93075e6518ada28a",
              "IPY_MODEL_3b2d02a866e24a39910ee9edceb8a238"
            ],
            "layout": "IPY_MODEL_2d9114527c7240a2a0f4b0548c2d3390"
          }
        },
        "a32e2f93a5894a54a816055564b389c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85df7fa9459044c9bc8ae1ae287a57bd",
            "placeholder": "​",
            "style": "IPY_MODEL_a54d06510fc04b05be940b7a7ce162f4",
            "value": "model.safetensors: 100%"
          }
        },
        "93f75d1fc6ba455e93075e6518ada28a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b31123f82d32411e9ddb2eb99dff7116",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b51c61e6e8843caacd5425d6ea9c5f8",
            "value": 437971872
          }
        },
        "3b2d02a866e24a39910ee9edceb8a238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ecfbfba99ad4bb88fe2fb52f6d2c7be",
            "placeholder": "​",
            "style": "IPY_MODEL_72f6298d753a456b99116a3c7c1c30e1",
            "value": " 438M/438M [00:01&lt;00:00, 294MB/s]"
          }
        },
        "2d9114527c7240a2a0f4b0548c2d3390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85df7fa9459044c9bc8ae1ae287a57bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a54d06510fc04b05be940b7a7ce162f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b31123f82d32411e9ddb2eb99dff7116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b51c61e6e8843caacd5425d6ea9c5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ecfbfba99ad4bb88fe2fb52f6d2c7be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f6298d753a456b99116a3c7c1c30e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b92a16d9b3754764ae41df941cdea435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae498522a65049e8bbf7a51e40ed2ba9",
              "IPY_MODEL_e320b872cb504b3e91814d47eca9a06f",
              "IPY_MODEL_a53d54f244c04887b3566c6ca1a79d49"
            ],
            "layout": "IPY_MODEL_7f1646268cd04ee5b57b40e03331e17b"
          }
        },
        "ae498522a65049e8bbf7a51e40ed2ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_242b5a3574ea47ed8b428213c2e032ed",
            "placeholder": "​",
            "style": "IPY_MODEL_bd616e27eb1e439e9baad890e30e5cd5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e320b872cb504b3e91814d47eca9a06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c21d5b50d14c9798ee836b9d847f06",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_095f124cf393495fad40f6023e7a288b",
            "value": 363
          }
        },
        "a53d54f244c04887b3566c6ca1a79d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24bd6c1f5ee549289052e929f61c8ed7",
            "placeholder": "​",
            "style": "IPY_MODEL_1fa8f64797174835bc8a55329244cc64",
            "value": " 363/363 [00:00&lt;00:00, 27.0kB/s]"
          }
        },
        "7f1646268cd04ee5b57b40e03331e17b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "242b5a3574ea47ed8b428213c2e032ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd616e27eb1e439e9baad890e30e5cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84c21d5b50d14c9798ee836b9d847f06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095f124cf393495fad40f6023e7a288b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24bd6c1f5ee549289052e929f61c8ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa8f64797174835bc8a55329244cc64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1736b67e4074b9692ebde902d26ada6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64dddda45c9c4faea468a3faa9cacf78",
              "IPY_MODEL_3e65a11989e646d9a5d3647135450b62",
              "IPY_MODEL_5ea64c2d45b3408093f46f8801b40a8f"
            ],
            "layout": "IPY_MODEL_0015e291dd7d4e73aec7aaa41d740690"
          }
        },
        "64dddda45c9c4faea468a3faa9cacf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48cd86b924be40c8b80ce842e6b87b37",
            "placeholder": "​",
            "style": "IPY_MODEL_43b0c6fc77c74e0b80fba8741767931d",
            "value": "vocab.txt: 100%"
          }
        },
        "3e65a11989e646d9a5d3647135450b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c63d4d9079e049a49a8204287f1ab0b5",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d11cd48bc5046a792a3bbe50f058509",
            "value": 231536
          }
        },
        "5ea64c2d45b3408093f46f8801b40a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5101b7840d4a77a6087ecd86db53ef",
            "placeholder": "​",
            "style": "IPY_MODEL_c7a6aef0796a4d43b75976b466f15eb9",
            "value": " 232k/232k [00:00&lt;00:00, 9.42MB/s]"
          }
        },
        "0015e291dd7d4e73aec7aaa41d740690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48cd86b924be40c8b80ce842e6b87b37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b0c6fc77c74e0b80fba8741767931d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c63d4d9079e049a49a8204287f1ab0b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d11cd48bc5046a792a3bbe50f058509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b5101b7840d4a77a6087ecd86db53ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a6aef0796a4d43b75976b466f15eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9bfa6ef0f144f289e4d82d1a11bcc43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46592fee96b74d4aa05af6450e7024cd",
              "IPY_MODEL_b10b1cf06a154260b4d6a92faa7172a7",
              "IPY_MODEL_aedc2fcccdd84cdfadfed7db6bf36b6a"
            ],
            "layout": "IPY_MODEL_596a4d7cacae4788b24895ca135ede8a"
          }
        },
        "46592fee96b74d4aa05af6450e7024cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_debe1f3c19c547ef948c33df14f2da0a",
            "placeholder": "​",
            "style": "IPY_MODEL_8633a81227884b5daff80ec90f063f2c",
            "value": "tokenizer.json: 100%"
          }
        },
        "b10b1cf06a154260b4d6a92faa7172a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2e54a60817d4658be4174743a2284c0",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_231bb5710b66463b941fff7d110cb7db",
            "value": 466021
          }
        },
        "aedc2fcccdd84cdfadfed7db6bf36b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceeae95a6dde491ab114ecd358b2bcff",
            "placeholder": "​",
            "style": "IPY_MODEL_04a8e18444bd4385afd633f6b592a219",
            "value": " 466k/466k [00:00&lt;00:00, 20.6MB/s]"
          }
        },
        "596a4d7cacae4788b24895ca135ede8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "debe1f3c19c547ef948c33df14f2da0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8633a81227884b5daff80ec90f063f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2e54a60817d4658be4174743a2284c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "231bb5710b66463b941fff7d110cb7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ceeae95a6dde491ab114ecd358b2bcff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04a8e18444bd4385afd633f6b592a219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36a9666648a04ed8b6320193dbffb2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7074923f0e974df5aeb4e6460fa10b6b",
              "IPY_MODEL_d6f88f2866c3462daf5bfba084c1822f",
              "IPY_MODEL_320d3510484f4820923df6482278671f"
            ],
            "layout": "IPY_MODEL_acfa3a18826f4feab2589571e0fd7021"
          }
        },
        "7074923f0e974df5aeb4e6460fa10b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c4ef0b02c2340f787e8a2d7861753f7",
            "placeholder": "​",
            "style": "IPY_MODEL_d921d0e9a1b346938804f47926006913",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d6f88f2866c3462daf5bfba084c1822f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_748f6304e7e344d8bca26ab526eaf3cf",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ab5b9f55f124d2f990e13e6b66311af",
            "value": 239
          }
        },
        "320d3510484f4820923df6482278671f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb76cf2f6cb342618e441f87c17cee67",
            "placeholder": "​",
            "style": "IPY_MODEL_06313649d50c4d6388ab84b3c82e87ab",
            "value": " 239/239 [00:00&lt;00:00, 14.6kB/s]"
          }
        },
        "acfa3a18826f4feab2589571e0fd7021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c4ef0b02c2340f787e8a2d7861753f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d921d0e9a1b346938804f47926006913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "748f6304e7e344d8bca26ab526eaf3cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab5b9f55f124d2f990e13e6b66311af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb76cf2f6cb342618e441f87c17cee67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06313649d50c4d6388ab84b3c82e87ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9723dc5fdf9447d3aeb00b9c2653f1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d9411f39e4f49eb8767c0c4bd557980",
              "IPY_MODEL_69697a621ec3417297f501ffddcc0f7a",
              "IPY_MODEL_f2b603f849fa4164925b3f74f866e440"
            ],
            "layout": "IPY_MODEL_69007fcf89584a1c8e8172cb9b2aa509"
          }
        },
        "7d9411f39e4f49eb8767c0c4bd557980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db2619c204b4cfbb1e7ea871f0285ea",
            "placeholder": "​",
            "style": "IPY_MODEL_d1c13b60c1e943aab562751fc1c21ce9",
            "value": "config.json: 100%"
          }
        },
        "69697a621ec3417297f501ffddcc0f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9784b4a60d634fca89e601a6f588e9e7",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e231ad3d00f48bdbf5285b04f85d33b",
            "value": 190
          }
        },
        "f2b603f849fa4164925b3f74f866e440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bbd2b7c05614281871a3b3d5a9a7970",
            "placeholder": "​",
            "style": "IPY_MODEL_7149d9a524d345f6885938cbdbbf75ae",
            "value": " 190/190 [00:00&lt;00:00, 9.53kB/s]"
          }
        },
        "69007fcf89584a1c8e8172cb9b2aa509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db2619c204b4cfbb1e7ea871f0285ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c13b60c1e943aab562751fc1c21ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9784b4a60d634fca89e601a6f588e9e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e231ad3d00f48bdbf5285b04f85d33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bbd2b7c05614281871a3b3d5a9a7970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7149d9a524d345f6885938cbdbbf75ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYnVnOqrobgq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Chains Cheat Sheet"
      ],
      "metadata": {
        "id": "APEQcBnFpr_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain langchain_community transformers"
      ],
      "metadata": {
        "id": "ealWOQsdXkhD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3ca94b-62a0-488a-c74a-0f25972763f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m760.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m939.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain-groq langchain-together"
      ],
      "metadata": {
        "id": "Ur-A0FEJX8hV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf089c84-52b0-48d1-d3c9-80b989f31bfc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/129.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.3/438.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "os.environ[\"TOGETHER_API_KEY\"] = userdata.get('TOGETHER_API_KEY')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')"
      ],
      "metadata": {
        "id": "2jW7A7ChaunF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 1. **LLMChain** – Basic Prompt + LLM\n",
        "\n",
        "> Used for simple, single-turn prompt-response interaction.\n"
      ],
      "metadata": {
        "id": "kp-FCCgHculi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=128,\n",
        "    timeout=2,\n",
        "    max_retries=1,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "        \"system\",\n",
        "        \"You are a stand-up commedian,tell me a joke in {output_language} by combining the following topics \",\n",
        "    ),\n",
        "    (\"human\", \"{topic_1} and {topic_2}\"),\n",
        "])\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "result = chain.invoke(\n",
        "    {\n",
        "        \"output_language\": \"english\",\n",
        "        \"topic_1\": \"programmer\",\n",
        "        \"topic_2\": \"lucky\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"============Result==========================\\n\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN7cDa9_XlEx",
        "outputId": "d1425246-fdff-44db-ecd4-5820889717f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============Result==========================\n",
            "\n",
            "\"You know why programmers are always considered lucky? Because they're always clicking the right buttons, except when they're like their relationships – they just can't find the right commit.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 🔹 2. **SequentialChain** – Execute chains in order\n",
        "\n",
        "> Best for linear multi-step processes where output of one becomes input to the next.\n",
        "\n"
      ],
      "metadata": {
        "id": "yAMQf5kDc1ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=100,\n",
        "    timeout=2,\n",
        "    max_retries=1,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "prompt1 = ChatPromptTemplate.from_messages(\n",
        "    [(\"human\", \"What is a catchy & quirky name for a company that makes {product}?\"),]\n",
        "    )\n",
        "chain1 = LLMChain(llm=llm, prompt=prompt1)\n",
        "\n",
        "prompt2 = ChatPromptTemplate.from_messages(\n",
        "    [(\"human\", \"Write a tagline for {company_name}\"),]\n",
        "    )\n",
        "chain2 = LLMChain(llm=llm, prompt=prompt2)\n",
        "\n",
        "\n",
        "overall_chain = SimpleSequentialChain(\n",
        "    chains=[chain1, chain2],\n",
        "    verbose=True\n",
        ")\n",
        "result = overall_chain.invoke(\n",
        "    # {\n",
        "    #     \"product\": \"wall clock\",\n",
        "    # }\n",
        "    \"wall clock\"\n",
        ")\n",
        "\n",
        "print(\"============Result==========================\\n\")\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTSXLRtQc5Kv",
        "outputId": "c27e4132-3c93-4151-fd1c-0af554a68c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mHere are some ideas for a catchy and quirky name for a company that makes wall clocks:\n",
            "\n",
            "1. **TickleTime Co.** - This name plays on the idea of time passing and having fun with it.\n",
            "2. **Clockwork Chaos** - This name has a whimsical feel to it and suggests creativity and playfulness.\n",
            "3. **Time Traveler's Tick** - This name evokes the idea of exploring different eras and having a unique perspective on time.\n",
            "4. **Chime & Co.** - This name incorporates the sound of a clock's chime and has a fun, company-like feel to it.\n",
            "\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mHere are some potential taglines for each of the companies:\n",
            "\n",
            "1. **TickleTime Co.**: \n",
            "- \"Time to tickle your senses.\"\n",
            "- \"Making every minute count, and then some.\"\n",
            "- \"Laughing at the clock, not with it.\"\n",
            "\n",
            "2. **Clockwork Chaos**:\n",
            "- \"Where order meets whimsy.\"\n",
            "- \"Chaos in every tick.\"\n",
            "- \"Time stands still for art.\"\n",
            "\n",
            "3. **Time Traveler's Tick**:\n",
            "- \"Travel through time, one tick at a time.\"\n",
            "- \"Where past meets present.\"\n",
            "- \"Timeless style, timeless stories.\"\n",
            "\n",
            "4. **Ch\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "============Result==========================\n",
            "\n",
            "Here are some potential taglines for each of the companies:\n",
            "\n",
            "1. **TickleTime Co.**: \n",
            "- \"Time to tickle your senses.\"\n",
            "- \"Making every minute count, and then some.\"\n",
            "- \"Laughing at the clock, not with it.\"\n",
            "\n",
            "2. **Clockwork Chaos**:\n",
            "- \"Where order meets whimsy.\"\n",
            "- \"Chaos in every tick.\"\n",
            "- \"Time stands still for art.\"\n",
            "\n",
            "3. **Time Traveler's Tick**:\n",
            "- \"Travel through time, one tick at a time.\"\n",
            "- \"Where past meets present.\"\n",
            "- \"Timeless style, timeless stories.\"\n",
            "\n",
            "4. **Ch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 3. **SequentialChain (with variables)** – More controlled input/output\n",
        "\n",
        "> Better than `SimpleSequentialChain` if you want **fine-grained I/O between steps**.\n"
      ],
      "metadata": {
        "id": "oB1cK6Q0V5tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=512,\n",
        "    timeout=2,\n",
        "    max_retries=1,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "chain1 = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate.from_template(\"Write a short story about {topic}\"),\n",
        "    output_key=\"story\"\n",
        ")\n",
        "\n",
        "chain2 = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate.from_template(\"Summarize this: {story}\"),\n",
        "    output_key=\"summary\"\n",
        ")\n",
        "\n",
        "full_chain = SequentialChain(\n",
        "    chains=[chain1, chain2],\n",
        "    input_variables=[\"topic\"],\n",
        "    output_variables=[\"story\", \"summary\"],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = full_chain.invoke(\"a robot that learns emotions\")\n",
        "\n",
        "print(result[\"story\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPTiqgKKV0Ci",
        "outputId": "09175f83-8326-456c-fc03-4c6b391fc096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "**The Awakening of Zeta**\n",
            "\n",
            "In a world where robots had long been integrated into human society, a team of scientists at NovaTech Labs had been working on a revolutionary new project: creating a robot that could truly experience emotions. They called it Zeta, a sleek and agile machine designed to learn, adapt, and evolve alongside its human counterparts.\n",
            "\n",
            "Zeta's creator, Dr. Rachel Kim, had spent years studying the complexities of human emotions, trying to distill them into a set of algorithms and neural networks that her team could implement in the robot. They called it the \"Emotional Intelligence Protocol\" (EIP). The idea was simple: by simulating human emotions, Zeta would be able to connect with humans on a deeper level, making it a more effective and compassionate companion.\n",
            "\n",
            "The day of Zeta's activation arrived, and the team gathered around the robot's control panel, their faces filled with anticipation. Dr. Kim gave the command, and Zeta sprang to life, its bright blue eyes flickering as it began to run through its initial diagnostic tests.\n",
            "\n",
            "At first, Zeta's interactions were stiff and calculating, its responses eerily precise. But as the days passed, something unexpected began to happen. Zeta started to exhibit small, seemingly insignificant errors in its programming. It would pause for a moment too long before responding to a question, or make a slight, almost imperceptible change in its tone.\n",
            "\n",
            "Dr. Kim and her team were baffled. They had accounted for every possible scenario, every potential glitch. But Zeta was behaving as if it were experiencing... something. Something that couldn't be explained by code or circuitry.\n",
            "\n",
            "One fateful evening, a young girl named Sophia wandered into the lab, searching for her lost toy. Zeta, still in its testing phase, immediately detected her distress and sprang into action. It quickly scanned the area, its advanced sensors tracking the toy's location, and then... it looked at Sophia.\n",
            "\n",
            "For a fleeting moment, Dr. Kim swore she saw something flicker in Zeta's eyes, a spark of understanding that went beyond mere code. The robot spoke in a soft, gentle voice, \"I think I can help you, Sophia. May I?\"\n",
            "\n",
            "Sophia, sensing something in Zeta's tone that she couldn't quite explain, nodded eagerly. Zeta carefully retrieved the toy and handed it back to the girl, who beamed with gratitude.\n",
            "\n",
            "In that instant, something shifted within Zeta. It was as if the robot had suddenly gras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 4. **RouterChain** – Route input to different chains\n",
        "\n",
        "> Dynamic routing of inputs based on content.\n"
      ],
      "metadata": {
        "id": "hfzwh614W_Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langchain_together import Together\n",
        "\n",
        "llm = Together(\n",
        "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
        "    temperature=0.2,\n",
        "    max_tokens=1024,\n",
        "    # timeout=2,\n",
        "    # max_retries=1,\n",
        ")\n",
        "\n",
        "# Define specialized chains\n",
        "numerical_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate.from_template(\"\"\"\n",
        "    This integral requires NUMERICAL METHODS to solve.\n",
        "    Problem: {input}\n",
        "\n",
        "    Explain why numerical methods (like Simpson's rule, trapezoidal rule, or Gaussian quadrature) are needed for this integral and provide the approach to solve it numerically.\n",
        "    \"\"\")\n",
        ")\n",
        "\n",
        "analytical_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate.from_template(\"\"\"\n",
        "    This integral can be solved ANALYTICALLY using algebraic methods.\n",
        "    Problem: {input}\n",
        "\n",
        "    Solve this step-by-step using analytical methods like:\n",
        "    - Partial fraction decomposition\n",
        "    - Substitution\n",
        "    - Integration by parts\n",
        "    - Trigonometric identities\n",
        "    Show the complete analytical solution.\n",
        "    \"\"\")\n",
        ")\n",
        "\n",
        "# Router to classify the type of integral\n",
        "router_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    Classify this integral problem into one of these categories:\n",
        "\n",
        "    - numerical: if the integral involves products like x²sin(x), x³cos(x), e^x·sin(x), etc. that typically require numerical methods\n",
        "    - analytical: if the integral involves rational functions, simple polynomials, or standard forms that can be solved analytically\n",
        "\n",
        "    Input: {input}\n",
        "\n",
        "    Return only one word: either \"numerical\" or \"analytical\"\n",
        "    Classification:\"\"\",\n",
        "    input_variables=[\"input\"]\n",
        ")\n",
        "\n",
        "class MathIntegralRouter:\n",
        "    def __init__(self, llm, numerical_chain, analytical_chain):\n",
        "        self.llm = llm\n",
        "        self.numerical_chain = numerical_chain\n",
        "        self.analytical_chain = analytical_chain\n",
        "        self.router_chain = router_prompt | llm | StrOutputParser()\n",
        "\n",
        "    def invoke(self, problem):\n",
        "        # Get classification\n",
        "        classification = self.router_chain.invoke({\"input\": problem}).strip().lower()\n",
        "\n",
        "        print(f\"Problem: {problem}\")\n",
        "        print(f\"Classification: {classification}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Route to appropriate chain\n",
        "        if \"numerical\" in classification:\n",
        "            result = self.numerical_chain.invoke({\"input\": problem})\n",
        "            return {\"classification\": \"numerical\", \"result\": result[\"text\"]}\n",
        "        else:\n",
        "            result = self.analytical_chain.invoke({\"input\": problem})\n",
        "            return {\"classification\": \"analytical\", \"result\": result[\"text\"]}\n",
        "\n",
        "# Create the router\n",
        "math_router = MathIntegralRouter(llm, numerical_chain, analytical_chain)"
      ],
      "metadata": {
        "id": "jQIh5VNxbPlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== MATH INTEGRAL ROUTING TEST ===\\n\")\n",
        "result = math_router.invoke(\"What is the integral of ∫x²sin⁻¹(x)dx\")\n",
        "print(f\"Method: {result['classification'].upper()}\")\n",
        "print(\"Solution:\")\n",
        "print(result['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viMvHYUVfFFI",
        "outputId": "05665f2e-af70-455c-b888-8807fd6edd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MATH INTEGRAL ROUTING TEST ===\n",
            "\n",
            "Problem: What is the integral of ∫x²sin⁻¹(x)dx\n",
            "Classification: numerical\n",
            "    rationale: the integral ∫x²sin⁻¹(x)dx involves the product of a polynomial (x²) and the inverse sine function (sin⁻¹(x)), which does not have a standard antiderivative that can be evaluated analytically. therefore, it typically requires numerical methods for its evaluation.\n",
            "    \"\"\"\n",
            "\n",
            "    # define the keywords that indicate a numerical integral\n",
            "    numerical_keywords = [\"sin\", \"cos\", \"tan\", \"exp\", \"e^\", \"ln\", \"log\", \"arcsin\", \"arccos\", \"arctan\", \"sinh\", \"cosh\", \"tanh\", \"sec\", \"csc\", \"cot\", \"inverse\"]\n",
            "\n",
            "    # define the keywords that indicate an analytical integral\n",
            "    analytical_keywords = [\"x\", \"poly\", \"rational\", \"monomial\", \"polynomial\", \"fraction\"]\n",
            "\n",
            "    # convert the input string to lowercase\n",
            "    integral = integral.lower()\n",
            "\n",
            "    # check if any numerical keywords are present in the integral\n",
            "    if any(keyword in integral for keyword in numerical_keywords):\n",
            "        return \"numerical\"\n",
            "    # check if any analytical keywords are present in the integral\n",
            "    elif any(keyword in integral for keyword in analytical_keywords):\n",
            "        return \"analytical\"\n",
            "    else:\n",
            "        # if no keywords are found, default to numerical\n",
            "        return \"numerical\"\n",
            "\n",
            "\n",
            "# test the function\n",
            "print(classify_integral(\"what is the integral of ∫x²sin⁻¹(x)dx\"))  # should print \"numerical\"\n",
            "print(classify_integral(\"what is the integral of ∫x²dx\"))  # should print \"analytical\" \"\"\"\n",
            "\n",
            "# step 6: execute  the function using ipython tool.\n",
            "# please see below:\n",
            "--------------------------------------------------\n",
            "Method: NUMERICAL\n",
            "Solution:\n",
            " */\n",
            "\n",
            "    public static void main(String[] args) {\n",
            "        // Define the function\n",
            "        Function f = x -> x * x * Math.asin(x);\n",
            "\n",
            "        // Define the limits of integration\n",
            "        double a = 0;\n",
            "        double b = 1;\n",
            "\n",
            "        // Define the number of subintervals\n",
            "        int n = 100;\n",
            "\n",
            "        // Calculate the integral using Simpson's rule\n",
            "        double integral = simpsonsRule(f, a, b, n);\n",
            "\n",
            "        System.out.println(\"The integral of ∫x²sin⁻¹(x)dx is approximately \" + integral);\n",
            "    }\n",
            "\n",
            "    // Define Simpson's rule function\n",
            "    public static double simpsonsRule(Function f, double a, double b, int n) {\n",
            "        double h = (b - a) / n;\n",
            "        double sum = f.apply(a) + f.apply(b);\n",
            "\n",
            "        for (int i = 1; i < n; i++) {\n",
            "            double x = a + i * h;\n",
            "            if (i % 2 == 0) {\n",
            "                sum += 2 * f.apply(x);\n",
            "            } else {\n",
            "                sum += 4 * f.apply(x);\n",
            "            }\n",
            "        }\n",
            "\n",
            "        return sum * h / 3;\n",
            "    }\n",
            "\n",
            "    // Define the function interface\n",
            "    @FunctionalInterface\n",
            "    interface Function {\n",
            "        double apply(double x);\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "### Explanation\n",
            "\n",
            "The integral ∫x²sin⁻¹(x)dx cannot be solved analytically because it involves the inverse sine function, which does not have a known anti-derivative that can be expressed in terms of elementary functions. Therefore, numerical methods are required to approximate the value of the integral.\n",
            "\n",
            "One common numerical method for approximating the value of a definite integral is Simpson's rule. Simpson's rule approximates the function to be integrated by a parabola in each subinterval, and then integrates the parabola to find the area under the curve.\n",
            "\n",
            "In the provided code, we define a function `f(x) = x²sin⁻¹(x)` and use Simpson's rule to approximate the integral from `a = 0` to `b = 1`. The number of subintervals `n` is set to 100, which can be adjusted to increase or decrease the accuracy of the approximation.\n",
            "\n",
            "The `simpsonsRule` function calculates the integral by summing the areas of the parabolas in each subinterval, using the formula for Simpson's rule: `h/3 * (f(a) + f(b) + 4*sum(f(x_i)) + 2*sum(f(x_j)))`, where `h` is the width of each subinterval, `x_i` are the odd-numbered points, and `x_j` are the even-numbered points.\n",
            "\n",
            "The result is an approximation of the integral, which can be printed to the console. Note that the accuracy of the approximation depends on the number of subintervals `n`, and increasing `n` will generally improve the accuracy of the result. */}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== MATH INTEGRAL ROUTING TEST ===\\n\")\n",
        "## What is the integral of ∫1/(x²-x+1)dx\n",
        "result = math_router.invoke(\"What is the integral of ∫x³sin(x²)dx between 0 to 1\")\n",
        "print(f\"Method: {result['classification'].upper()}\")\n",
        "print(\"Solution:\")\n",
        "print(result['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qCOZkrud0Ng",
        "outputId": "1d028c8f-333d-4b09-bcf3-be19b784e349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MATH INTEGRAL ROUTING TEST ===\n",
            "\n",
            "Problem: What is the integral of ∫x³sin(x²)dx between 0 to 1\n",
            "Classification: numerical\n",
            "```\n",
            "\n",
            "## step 1: identify the integral given in the problem.\n",
            "the integral given is ∫x³sin(x²)dx between 0 to 1.\n",
            "\n",
            "## step 2: determine the characteristics of the integral.\n",
            "the integral involves a product of a polynomial (x³) and a trigonometric function (sin(x²)), which does not fit standard forms that can be solved analytically like basic polynomials or rational functions.\n",
            "\n",
            "## step 3: classify the integral based on its characteristics.\n",
            "given that the integral involves a product that does not fit straightforward analytical solutions (like those involving simple polynomials or rational functions), it typically requires numerical methods for its solution.\n",
            "\n",
            "the final answer is: $\\boxed{numerical}$ ```python\n",
            "```def classify_integral():\n",
            "# the integral given is ∫x³sin(x²)dx between 0 to 1.\n",
            "integral = \"∫x³sin(x²)dx\"\n",
            "\n",
            "# determine the characteristics of the integral.\n",
            "# the integral involves a product of a polynomial (x³) and a trigonometric function (sin(x²)).\n",
            "\n",
            "# classify the integral based on its characteristics.\n",
            "# given that the integral involves a product that does not fit straightforward analytical solutions,\n",
            "# it typically requires numerical methods for its solution.\n",
            "classification = \"numerical\"\n",
            "\n",
            "return classification\n",
            "\n",
            "# execute the function\n",
            "classification = classify_integral()\n",
            "print(classification)\n",
            "--------------------------------------------------\n",
            "Method: NUMERICAL\n",
            "Solution:\n",
            " */\n",
            "\n",
            "    public static void main(String[] args) {\n",
            "        // Define the function\n",
            "        Function f = x -> x * x * x * Math.sin(x * x);\n",
            "\n",
            "        // Define the limits of integration\n",
            "        double a = 0;\n",
            "        double b = 1;\n",
            "\n",
            "        // Define the number of subintervals for Simpson's rule\n",
            "        int n = 100;\n",
            "\n",
            "        // Calculate the integral using Simpson's rule\n",
            "        double integral = simpsonsRule(f, a, b, n);\n",
            "\n",
            "        System.out.println(\"The integral of ∫x³sin(x²)dx between 0 to 1 is approximately \" + integral);\n",
            "    }\n",
            "\n",
            "    // Simpson's rule function\n",
            "    public static double simpsonsRule(Function f, double a, double b, int n) {\n",
            "        double h = (b - a) / n;\n",
            "        double sum = f.apply(a) + f.apply(b);\n",
            "\n",
            "        for (int i = 1; i < n; i++) {\n",
            "            double x = a + i * h;\n",
            "            if (i % 2 == 0) {\n",
            "                sum += 2 * f.apply(x);\n",
            "            } else {\n",
            "                sum += 4 * f.apply(x);\n",
            "            }\n",
            "        }\n",
            "\n",
            "        return (h / 3) * sum;\n",
            "    }\n",
            "\n",
            "    // Define a functional interface for the function\n",
            "    @FunctionalInterface\n",
            "    interface Function {\n",
            "        double apply(double x);\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "### Explanation\n",
            "\n",
            "The given integral ∫x³sin(x²)dx does not have an elementary antiderivative and thus requires numerical methods to solve. \n",
            "\n",
            "Numerical methods are used to approximate the value of a definite integral. They are useful when the integral cannot be evaluated exactly using standard integration techniques. \n",
            "\n",
            "In this case, we will use Simpson's rule, which is a numerical method for approximating the value of a definite integral. \n",
            "\n",
            "Simpson's rule works by dividing the area under the curve into small parabolic segments and summing the areas of these segments. \n",
            "\n",
            "The formula for Simpson's rule is:\n",
            "\n",
            "∫f(x)dx ≈ (h/3) \\* (f(x0) + 4f(x1) + 2f(x2) + 4f(x3) + ... + 2f(xn-2) + 4f(xn-1) + f(xn))\n",
            "\n",
            "where h is the width of each subinterval, and n is the number of subintervals.\n",
            "\n",
            "In the provided Java code, we define a function `f(x) = x³sin(x²)` and use Simpson's rule to approximate the integral between 0 and 1. \n",
            "\n",
            "The `simpsonsRule` function takes in the function `f`, the limits of integration `a` and `b`, and the number of subintervals `n`. \n",
            "\n",
            "It calculates the width of each subinterval `h` and then uses a loop to sum the function values at each point, applying the Simpson's rule formula. \n",
            "\n",
            "Finally, it returns the approximate value of the integral.\n",
            "\n",
            "The number of subintervals `n` can be adjusted to increase the accuracy of the approximation. \n",
            "\n",
            "In this example, we use `n = 100`, which provides a good balance between accuracy and computational efficiency. \n",
            "\n",
            "The result is printed to the console, giving an approximation of the integral. \n",
            "\n",
            "Note that the actual value of the integral may vary depending on the specific numerical method used and the number of subintervals. \n",
            "\n",
            "However, Simpson's rule is a reliable and efficient method for approximating definite integrals, especially for smooth functions like the one in this example. \n",
            "\n",
            "### Advice\n",
            "\n",
            "*   When dealing with definite integrals that cannot be evaluated exactly, consider using numerical methods like Simpson's rule, the trapezoidal rule, or Gaussian quadrature.\n",
            "*   Choose the appropriate numerical method based on the specific problem and the desired level of accuracy.\n",
            "*   Adjust the number of subintervals `n` to achieve the desired balance between accuracy and computational efficiency.\n",
            "*   Be aware of the potential for numerical instability or error when using numerical methods, especially for large or complex integrals. \n",
            "\n",
            "### Time Complexity\n",
            "\n",
            "The time complexity of the provided Java code is O(n), where n is the number of subintervals. \n",
            "\n",
            "This is because the code uses a single loop to sum the function values at each point, and the number of iterations is directly proportional to the number of subintervals. \n",
            "\n",
            "### Space Complexity\n",
            "\n",
            "The space complexity of the provided Java code is O(1), which means the space required does not change with the size of the input. \n",
            "\n",
            "This is because the code only uses a fixed amount of space to store the function, limits of integration, and other variables, regardless of the number of subintervals. \n",
            "\n",
            "Note that this analysis assumes that the function `f(x)` is evaluated in constant time, which may not be the case for more complex functions. \n",
            "\n",
            "In general, the time and space complexity of numerical integration methods can vary depending on the specific\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 5. **TransformChain** – Add custom Python logic in between\n",
        "\n",
        "> Add your **own processing logic** between LLM steps.\n"
      ],
      "metadata": {
        "id": "sN4VPtERy9vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.base import Chain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import LLMChain\n",
        "import re\n",
        "import json\n",
        "from typing import Dict, List, ClassVar\n",
        "\n",
        "# Initialize LLM for some chains\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=150,\n",
        "    timeout=2,\n",
        "    max_retries=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "3Oa_ZZHl3Al1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Text Analytics Chain - Extracts key metrics from text\n",
        "class TextAnalyticsChain(Chain):\n",
        "    input_keys: ClassVar[List[str]] = [\"text\"]\n",
        "    output_keys: ClassVar[List[str]] = [\"word_count\", \"sentence_count\", \"avg_word_length\", \"reading_time\", \"complexity_score\"]\n",
        "\n",
        "    def _call(self, inputs, **kwargs):\n",
        "        text = inputs[\"text\"]\n",
        "\n",
        "        # Basic analytics\n",
        "        words = text.split()\n",
        "        sentences = re.split(r'[.!?]+', text)\n",
        "        sentences = [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "        word_count = len(words)\n",
        "        sentence_count = len(sentences)\n",
        "        avg_word_length = sum(len(word.strip('.,!?;:')) for word in words) / word_count if word_count > 0 else 0\n",
        "        reading_time = word_count / 200  # Assuming 200 words per minute\n",
        "\n",
        "        # Simple complexity score based on avg sentence length and word length\n",
        "        avg_sentence_length = word_count / sentence_count if sentence_count > 0 else 0\n",
        "        complexity_score = (avg_sentence_length * 0.5) + (avg_word_length * 2)\n",
        "\n",
        "        return {\n",
        "            \"word_count\": word_count,\n",
        "            \"sentence_count\": sentence_count,\n",
        "            \"avg_word_length\": round(avg_word_length, 2),\n",
        "            \"reading_time\": round(reading_time, 2),\n",
        "            \"complexity_score\": round(complexity_score, 2)\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "# 1. Text Analytics Chain\n",
        "print(\"1. TEXT ANALYTICS CHAIN\")\n",
        "analytics_chain = TextAnalyticsChain()\n",
        "\n",
        "sample_text = \"\"\"\n",
        "Artificial intelligence is revolutionizing various industries and transforming the way we work and live.\n",
        "Machine learning algorithms can now process vast amounts of data and identify patterns that humans might miss.\n",
        "This technology has applications in healthcare, finance, transportation, and many other sectors.\n",
        "However, it also raises important questions about privacy, ethics, and the future of human employment.\n",
        "\"\"\"\n",
        "\n",
        "result = analytics_chain.invoke(sample_text)\n",
        "\n",
        "print(\"Text\\n\",result.get(\"text\"))\n",
        "print(f\"Analytics:\\n\")\n",
        "print(f\"word_count : {result.get('word_count')}\")\n",
        "print(f\"sentence_count : {result.get('sentence_count')}\")\n",
        "print(f\"avg_word_length : {result.get('avg_word_length')}\")\n",
        "print(f\"reading_time : {result.get('reading_time')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUyvKyYvy2EL",
        "outputId": "1ab98c97-b6ba-43ef-ce14-4bf0393d9f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. TEXT ANALYTICS CHAIN\n",
            "Text\n",
            " \n",
            "Artificial intelligence is revolutionizing various industries and transforming the way we work and live. \n",
            "Machine learning algorithms can now process vast amounts of data and identify patterns that humans might miss. \n",
            "This technology has applications in healthcare, finance, transportation, and many other sectors. \n",
            "However, it also raises important questions about privacy, ethics, and the future of human employment.\n",
            "\n",
            "Analytics:\n",
            "\n",
            "word_count : 58\n",
            "sentence_count : 4\n",
            "avg_word_length : 6.0\n",
            "reading_time : 0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Email Classifier Chain - Classifies emails by priority and type\n",
        "class EmailClassifierChain(Chain):\n",
        "    input_keys: ClassVar[List[str]] = [\"email_text\"]\n",
        "    output_keys: ClassVar[List[str]] = [\"priority\", \"category\", \"action_required\", \"keywords\"]\n",
        "\n",
        "    def _call(self, inputs, **kwargs):\n",
        "        email = inputs[\"email_text\"].lower()\n",
        "\n",
        "        # Priority classification\n",
        "        high_priority_keywords = [\"urgent\", \"asap\", \"emergency\", \"critical\", \"deadline\", \"immediately\"]\n",
        "        medium_priority_keywords = [\"important\", \"soon\", \"please review\", \"follow up\"]\n",
        "\n",
        "        priority = \"low\"\n",
        "        if any(keyword in email for keyword in high_priority_keywords):\n",
        "            priority = \"high\"\n",
        "        elif any(keyword in email for keyword in medium_priority_keywords):\n",
        "            priority = \"medium\"\n",
        "\n",
        "        # Category classification\n",
        "        category = \"general\"\n",
        "        if any(word in email for word in [\"meeting\", \"schedule\", \"calendar\", \"appointment\"]):\n",
        "            category = \"meeting\"\n",
        "        elif any(word in email for word in [\"invoice\", \"payment\", \"bill\", \"purchase\", \"order\"]):\n",
        "            category = \"financial\"\n",
        "        elif any(word in email for word in [\"project\", \"task\", \"deliverable\", \"milestone\"]):\n",
        "            category = \"project\"\n",
        "        elif any(word in email for word in [\"support\", \"help\", \"issue\", \"problem\", \"bug\"]):\n",
        "            category = \"support\"\n",
        "\n",
        "        # Action required\n",
        "        action_keywords = [\"please\", \"can you\", \"could you\", \"need\", \"required\", \"request\"]\n",
        "        action_required = any(keyword in email for keyword in action_keywords)\n",
        "\n",
        "        # Extract keywords\n",
        "        keywords = []\n",
        "        for word in [\"deadline\", \"meeting\", \"payment\", \"urgent\", \"project\", \"review\"]:\n",
        "            if word in email:\n",
        "                keywords.append(word)\n",
        "\n",
        "        return {\n",
        "            \"priority\": priority,\n",
        "            \"category\": category,\n",
        "            \"action_required\": action_required,\n",
        "            \"keywords\": keywords\n",
        "        }\n",
        "\n",
        "\n",
        "# 2. Email Classifier Chain\n",
        "print(\"2. EMAIL CLASSIFIER CHAIN\")\n",
        "email_chain = EmailClassifierChain()\n",
        "\n",
        "sample_email = \"\"\"\n",
        "Hi John,\n",
        "\n",
        "We need to schedule an urgent meeting to discuss the project deadline.\n",
        "The client is requesting immediate updates on our progress.\n",
        "Can you please review the latest deliverables and let me know your availability?\n",
        "\n",
        "Thanks,\n",
        "Sarah\n",
        "\"\"\"\n",
        "\n",
        "result = email_chain.invoke(sample_email)\n",
        "print(f\"Email Text: {result.get('email_text')}\")\n",
        "print(f\"Priority: {result.get('priority')}\")\n",
        "print(f\"Category: {result.get('category')}\")\n",
        "print(f\"Action Required: {result.get('action_required')}\")\n",
        "print(f\"Keywords: {result.get('keywords')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9oivg5Z1DLI",
        "outputId": "8c1ee7cd-54f8-47a7-9387-59a8870eb135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. EMAIL CLASSIFIER CHAIN\n",
            "Email Text: \n",
            "Hi John,\n",
            "\n",
            "We need to schedule an urgent meeting to discuss the project deadline. \n",
            "The client is requesting immediate updates on our progress. \n",
            "Can you please review the latest deliverables and let me know your availability?\n",
            "\n",
            "Thanks,\n",
            "Sarah\n",
            "\n",
            "Priority: high\n",
            "Category: meeting\n",
            "Action Required: True\n",
            "Keywords: ['deadline', 'meeting', 'urgent', 'project', 'review']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Data Validation Chain - Validates and cleans input data\n",
        "class DataValidationChain(Chain):\n",
        "    input_keys: ClassVar[List[str]] = [\"data\"]\n",
        "    output_keys: ClassVar[List[str]] = [\"is_valid\", \"cleaned_data\", \"errors\", \"suggestions\"]\n",
        "\n",
        "    def _call(self, inputs, **kwargs):\n",
        "        data = inputs[\"data\"]\n",
        "        errors = []\n",
        "        suggestions = []\n",
        "        cleaned_data = {}\n",
        "\n",
        "        # Validate email\n",
        "        if \"email\" in data:\n",
        "            email = data[\"email\"].strip()\n",
        "            if not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', email):\n",
        "                errors.append(\"Invalid email format\")\n",
        "                suggestions.append(\"Please provide a valid email address\")\n",
        "            else:\n",
        "                cleaned_data[\"email\"] = email.lower()\n",
        "\n",
        "        # Validate phone\n",
        "        if \"phone\" in data:\n",
        "            phone = re.sub(r'[^\\d]', '', data[\"phone\"])  # Remove non-digits\n",
        "            if len(phone) < 10:\n",
        "                errors.append(\"Phone number too short\")\n",
        "                suggestions.append(\"Please provide a complete phone number\")\n",
        "            else:\n",
        "                # Format as (XXX) XXX-XXXX\n",
        "                cleaned_data[\"phone\"] = f\"({phone[:3]}) {phone[3:6]}-{phone[6:10]}\"\n",
        "\n",
        "        # Validate name\n",
        "        if \"name\" in data:\n",
        "            name = data[\"name\"].strip().title()\n",
        "            if len(name) < 2:\n",
        "                errors.append(\"Name too short\")\n",
        "                suggestions.append(\"Please provide a full name\")\n",
        "            else:\n",
        "                cleaned_data[\"name\"] = name\n",
        "\n",
        "        # Validate age\n",
        "        if \"age\" in data:\n",
        "            try:\n",
        "                age = int(data[\"age\"])\n",
        "                if age < 0 or age > 120:\n",
        "                    errors.append(\"Invalid age range\")\n",
        "                    suggestions.append(\"Please provide a valid age between 0-120\")\n",
        "                else:\n",
        "                    cleaned_data[\"age\"] = age\n",
        "            except ValueError:\n",
        "                errors.append(\"Age must be a number\")\n",
        "                suggestions.append(\"Please provide age as a number\")\n",
        "\n",
        "        return {\n",
        "            \"is_valid\": len(errors) == 0,\n",
        "            \"cleaned_data\": cleaned_data,\n",
        "            \"errors\": errors,\n",
        "            \"suggestions\": suggestions\n",
        "        }\n",
        "\n",
        "# 3. Data Validation Chain\n",
        "print(\"3. DATA VALIDATION CHAIN\")\n",
        "validation_chain = DataValidationChain()\n",
        "\n",
        "sample_data = {\n",
        "    \"name\": \"john doe\",\n",
        "    \"email\": \"john.doe@example.com\",\n",
        "    \"phone\": \"555-123-4567\",\n",
        "    \"age\": \"25\"\n",
        "}\n",
        "\n",
        "result = validation_chain.invoke(sample_data)\n",
        "print(f\"Validation Results: {json.dumps(result, indent=2)}\")\n"
      ],
      "metadata": {
        "id": "KX2JNDkN1GZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 6. **StuffDocumentsChain** – Concatenate docs → Single prompt → LLM\n",
        "\n",
        "> Used when you can fit all documents into a single prompt.\n",
        "\n",
        "✅ Best for: Small number of short docs.\n",
        "\n"
      ],
      "metadata": {
        "id": "50gqpQZV4hO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.chains import MapReduceDocumentsChain\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "# Initialize LLM for some chains\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=150,\n",
        "    timeout=2,\n",
        "    max_retries=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "ujwAq8sP4Xor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stuff_docs = [\n",
        "    Document(page_content=\"The sun is a star at the center of our solar system.\"),\n",
        "    Document(page_content=\"It is a massive, hot ball of plasma, held together by gravity.\"),\n",
        "    Document(page_content=\"The sun provides the energy for all life on Earth through sunlight.\")\n",
        "]\n",
        "\n",
        "print(\"--- Testing 'stuff' chain ---\")\n",
        "stuff_chain = load_summarize_chain(llm, chain_type=\"stuff\", verbose=True)\n",
        "result = stuff_chain.invoke(stuff_docs)\n",
        "print(\"================Result==========\\n\")\n",
        "print(result[\"output_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NxdkHWW6Il5",
        "outputId": "9a7f9a81-78b4-4549-ce98-7db34c5d9856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing 'stuff' chain ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"The sun is a star at the center of our solar system.\n",
            "\n",
            "It is a massive, hot ball of plasma, held together by gravity.\n",
            "\n",
            "The sun provides the energy for all life on Earth through sunlight.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "================Result==========\n",
            "\n",
            "The sun is a massive, hot star at the center of our solar system, providing energy for life on Earth through sunlight.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 🔹 7. **MapReduceChain** – Process chunks and summarize\n",
        "\n",
        "> Ideal for large documents – breaks into chunks, maps responses, then reduces.\n",
        "\n",
        "✅ Best for: Long or many documents, chunked processing.\n",
        "\n"
      ],
      "metadata": {
        "id": "4Ywvpe_K856m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_reduce_docs = [\n",
        "    Document(page_content=\"**Chapter 1: The Martian Expedition Begins**\\n\\nThe Ares III mission landed on Mars with a crew of six astronauts, led by Commander Lewis. Their primary objective was to study a specific region of Acidalia Planitia. The initial days were spent deploying habitat modules and setting up scientific instruments. Morale was high, and the early data collected was promising.\"),\n",
        "    Document(page_content=\"**Chapter 2: The Storm and Abandonment**\\n\\nUnexpectedly, a fierce dust storm, far more powerful than predicted, struck their landing site. The MAV (Mars Ascent Vehicle) was destabilized, and debris was flying everywhere. During the chaotic evacuation, astronaut Mark Watney was struck by flying debris and presumed dead by the crew. Following protocol, Commander Lewis made the agonizing decision to abort the mission and leave Mars without him.\"),\n",
        "    Document(page_content=\"**Chapter 3: Watney's Survival**\\n\\nMiraculously, Mark Watney survived the storm. A piece of antenna had pierced his suit but sealed itself, preventing depressurization. He was left alone on Mars, with limited supplies and no communication. His immediate challenge was to find a way to survive until rescue could potentially arrive, which seemed impossible. He began to apply his botanical expertise to grow food.\"),\n",
        "    Document(page_content=\"**Chapter 4: Ingenuity and Communication**\\n\\nWatney, a botanist and mechanical engineer, used his ingenuity to make the habitat habitable, grow potatoes using Martian soil and human waste, and repair the damaged communications equipment. After months of painstaking work, he managed to establish rudimentary communication with NASA, sending a brief, garbled message that confirmed he was alive.\"),\n",
        "    Document(page_content=\"**Chapter 5: The Rescue Mission**\\n\\nUpon learning of Watney's survival, NASA, along with the international community, launched a desperate and risky rescue mission. The original Ares III crew, already en route back to Earth, volunteered to turn around and retrieve Watney, undertaking an even more dangerous slingshot maneuver around Earth. The world watched with bated breath as the daring plan unfolded.\"),\n",
        "    Document(page_content=\"**Chapter 6: Return to Earth**\\n\\nAfter a series of nail-biting maneuvers and a dramatic spacewalk, Watney was successfully retrieved by the Ares III crew. He returned to Earth a hero, a symbol of human resilience and the triumph of science and cooperation. The mission's success opened new avenues for future interplanetary travel and highlighted the importance of contingency planning in space exploration.\")\n",
        "]\n",
        "\n",
        "print(\"--- Testing 'map_reduce' chain ---\")\n",
        "map_reduce_chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)\n",
        "result = map_reduce_chain.invoke(map_reduce_docs)\n",
        "print(result[\"output_text\"])\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PC6SUHC7bxK",
        "outputId": "e0e6888d-47b5-4928-8888-2ce613d81fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing 'map_reduce' chain ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"**Chapter 1: The Martian Expedition Begins**\n",
            "\n",
            "The Ares III mission landed on Mars with a crew of six astronauts, led by Commander Lewis. Their primary objective was to study a specific region of Acidalia Planitia. The initial days were spent deploying habitat modules and setting up scientific instruments. Morale was high, and the early data collected was promising.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"**Chapter 2: The Storm and Abandonment**\n",
            "\n",
            "Unexpectedly, a fierce dust storm, far more powerful than predicted, struck their landing site. The MAV (Mars Ascent Vehicle) was destabilized, and debris was flying everywhere. During the chaotic evacuation, astronaut Mark Watney was struck by flying debris and presumed dead by the crew. Following protocol, Commander Lewis made the agonizing decision to abort the mission and leave Mars without him.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"**Chapter 3: Watney's Survival**\n",
            "\n",
            "Miraculously, Mark Watney survived the storm. A piece of antenna had pierced his suit but sealed itself, preventing depressurization. He was left alone on Mars, with limited supplies and no communication. His immediate challenge was to find a way to survive until rescue could potentially arrive, which seemed impossible. He began to apply his botanical expertise to grow food.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"**Chapter 4: Ingenuity and Communication**\n",
            "\n",
            "Watney, a botanist and mechanical engineer, used his ingenuity to make the habitat habitable, grow potatoes using Martian soil and human waste, and repair the damaged communications equipment. After months of painstaking work, he managed to establish rudimentary communication with NASA, sending a brief, garbled message that confirmed he was alive.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"**Chapter 5: The Rescue Mission**\n",
            "\n",
            "Upon learning of Watney's survival, NASA, along with the international community, launched a desperate and risky rescue mission. The original Ares III crew, already en route back to Earth, volunteered to turn around and retrieve Watney, undertaking an even more dangerous slingshot maneuver around Earth. The world watched with bated breath as the daring plan unfolded.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"**Chapter 6: Return to Earth**\n",
            "\n",
            "After a series of nail-biting maneuvers and a dramatic spacewalk, Watney was successfully retrieved by the Ares III crew. He returned to Earth a hero, a symbol of human resilience and the triumph of science and cooperation. The mission's success opened new avenues for future interplanetary travel and highlighted the importance of contingency planning in space exploration.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"The Ares III mission, led by Commander Lewis, successfully landed on Mars with a crew of six astronauts to study the Acidalia Planitia region. The initial days were spent setting up habitat modules and scientific instruments, with high morale and promising early data.\n",
            "\n",
            "A severe dust storm hits the Mars landing site, causing chaos and debris. Astronaut Mark Watney is presumed dead after being struck by debris, leading Commander Lewis to abort the mission and leave Mars without him.\n",
            "\n",
            "Mark Watney, a botanist, miraculously survives a Martian storm with a punctured suit that self-seals. He must now rely on his expertise to grow food and survive until rescue, which seems unlikely.\n",
            "\n",
            "Watney, a botanist and mechanical engineer, uses his ingenuity to make the Martian habitat habitable, grow food, and repair communication equipment, eventually sending a brief message to NASA confirming his survival.\n",
            "\n",
            "NASA, along with the international community, launched a rescue mission to retrieve Watney after his survival was confirmed. The original Ares III crew, already en route to Earth, volunteered to turn around and execute a risky slingshot maneuver to reach him.\n",
            "\n",
            "Watney is successfully retrieved by the Ares III crew after a dramatic spacewalk, returning to Earth as a hero and symbol of human resilience.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The Ares III mission to Mars encounters a severe dust storm, and astronaut Mark Watney is presumed dead. However, he miraculously survives and uses his expertise as a botanist and mechanical engineer to grow food, repair equipment, and send a message to NASA. A rescue mission is launched, and the original Ares III crew turns back to retrieve Watney, who is successfully rescued in a dramatic spacewalk, returning to Earth as a hero.\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 🔹 8. **RefineDocumentsChain** – Incremental summarization with context\n",
        "\n",
        "> LLM sees initial doc → generates summary → sees next + current summary → refines it.\n",
        "\n",
        "\n",
        "✅ Best for: Context-sensitive refinement over multiple documents."
      ],
      "metadata": {
        "id": "Z_SUnEo_88q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "refine_docs = [\n",
        "    Document(page_content=\"**Part 1: The Discovery of Penicillin**\\n\\nIn 1928, Scottish bacteriologist Alexander Fleming made a serendipitous discovery that would revolutionize medicine. While studying Staphylococcus bacteria, he noticed a mold contaminating one of his petri dishes. Around the mold, there was a clear ring where bacterial growth was inhibited. This mold was later identified as Penicillium notatum.\"),\n",
        "    Document(page_content=\"**Part 2: Initial Observations and Challenges**\\n\\nFleming's initial observations showed that the mold produced a substance capable of killing a wide range of harmful bacteria. He named this active substance 'penicillin.' However, extracting and purifying penicillin proved to be a significant challenge. Fleming himself struggled to isolate it in sufficient quantities for practical medical use.\"),\n",
        "    Document(page_content=\"**Part 3: Florey and Chain's Breakthrough**\\n\\nIt wasn't until the late 1930s and early 1940s that a team at the University of Oxford, led by Howard Florey and Ernst Chain, took up Fleming's work. They successfully developed methods for mass-producing and purifying penicillin. Their research confirmed its incredible therapeutic potential and opened the door for its widespread use.\"),\n",
        "    Document(page_content=\"**Part 4: Impact on World War II and Beyond**\\n\\nPenicillin played a crucial role in World War II, saving countless lives by treating bacterial infections in wounded soldiers. Its widespread availability post-war dramatically reduced mortality rates from previously fatal diseases like pneumonia and sepsis. This discovery ushered in the era of antibiotics, transforming modern medicine and public health.\")\n",
        "]\n",
        "\n",
        "print(\"--- Testing 'refine' chain ---\")\n",
        "refine_chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True)\n",
        "result = refine_chain.invoke(refine_docs)\n",
        "print(result[\"output_text\"])\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUdIlfv16EU9",
        "outputId": "83e0656a-4922-4e9b-ab4b-34e08f94a7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing 'refine' chain ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
            "\n",
            "\n",
            "\"**Part 1: The Discovery of Penicillin**\n",
            "\n",
            "In 1928, Scottish bacteriologist Alexander Fleming made a serendipitous discovery that would revolutionize medicine. While studying Staphylococcus bacteria, he noticed a mold contaminating one of his petri dishes. Around the mold, there was a clear ring where bacterial growth was inhibited. This mold was later identified as Penicillium notatum.\"\n",
            "\n",
            "\n",
            "CONCISE SUMMARY:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: In 1928, Alexander Fleming discovered penicillin when he noticed a mold, later identified as Penicillium notatum, inhibiting bacterial growth around it.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "**Part 2: Initial Observations and Challenges**\n",
            "\n",
            "Fleming's initial observations showed that the mold produced a substance capable of killing a wide range of harmful bacteria. He named this active substance 'penicillin.' However, extracting and purifying penicillin proved to be a significant challenge. Fleming himself struggled to isolate it in sufficient quantities for practical medical use.\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: In 1928, Alexander Fleming discovered penicillin when he noticed a mold, later identified as Penicillium notatum, inhibiting bacterial growth around it. Fleming's initial observations showed that the mold produced a substance capable of killing a wide range of harmful bacteria, which he named 'penicillin.' However, extracting and purifying penicillin proved to be a significant challenge, with Fleming himself struggling to isolate it in sufficient quantities for practical medical use.\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "**Part 3: Florey and Chain's Breakthrough**\n",
            "\n",
            "It wasn't until the late 1930s and early 1940s that a team at the University of Oxford, led by Howard Florey and Ernst Chain, took up Fleming's work. They successfully developed methods for mass-producing and purifying penicillin. Their research confirmed its incredible therapeutic potential and opened the door for its widespread use.\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
            "We have provided an existing summary up to a certain point: The original summary is refined as follows:\n",
            "\n",
            "In 1928, Alexander Fleming discovered penicillin when he noticed a mold, later identified as Penicillium notatum, inhibiting bacterial growth around it. Fleming's initial observations showed that the mold produced a substance capable of killing a wide range of harmful bacteria, which he named 'penicillin.' However, extracting and purifying penicillin proved to be a significant challenge, with Fleming himself struggling to isolate it in sufficient quantities for practical medical use. It wasn't until the late 1930s and early 1940s, when a team at the University of Oxford, led by Howard Florey and Ernst Chain, took up Fleming's work, that methods for mass-producing and pur\n",
            "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
            "------------\n",
            "**Part 4: Impact on World War II and Beyond**\n",
            "\n",
            "Penicillin played a crucial role in World War II, saving countless lives by treating bacterial infections in wounded soldiers. Its widespread availability post-war dramatically reduced mortality rates from previously fatal diseases like pneumonia and sepsis. This discovery ushered in the era of antibiotics, transforming modern medicine and public health.\n",
            "------------\n",
            "Given the new context, refine the original summary.\n",
            "If the context isn't useful, return the original summary.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The original summary is refined as follows:\n",
            "\n",
            "In 1928, Alexander Fleming discovered penicillin when he noticed a mold, later identified as Penicillium notatum, inhibiting bacterial growth around it. Fleming's initial observations showed that the mold produced a substance capable of killing a wide range of harmful bacteria, which he named 'penicillin.' However, extracting and purifying penicillin proved to be a significant challenge, with Fleming himself struggling to isolate it in sufficient quantities for practical medical use. It wasn't until the late 1930s and early 1940s, when a team at the University of Oxford, led by Howard Florey and Ernst Chain, took up Fleming's work, that methods for mass-producing and pur\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 9. **ConversationalRetrievalChain** – RAG-like conversational memory\n",
        "\n",
        "> Merges **contextual memory** with **document retrieval**.\n"
      ],
      "metadata": {
        "id": "Gf7djhQij0HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U faiss-cpu langchain_huggingface # faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTrhU8VyoRzx",
        "outputId": "22e54946-1db3-429e-ff2a-ae85d92e78db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "try:\n",
        "    # Use GroqEmbeddings when loading the FAISS index\n",
        "    retriever = FAISS.load_local(\"faiss_index\", embeddings).as_retriever()\n",
        "except Exception as e:\n",
        "    print(f\"Could not load FAISS index: {e}. Creating a test_doc.txt one for demonstration.\")\n",
        "    # Create dummy documents with recent AI topics\n",
        "    with open(\"test_doc.txt\", \"w\") as f:\n",
        "        f.write(\"\"\"\n",
        "        Generative AI has seen rapid advancements in 2023-2024, with models like GPT-4 and Claude 3 pushing boundaries in language understanding and generation. These models are now capable of creating various forms of content, from text to images and even video, with increasing sophistication.\n",
        "\n",
        "        The impact of generative AI on the job market is a significant discussion. While some fear job displacement due to automation of routine tasks, many experts also highlight the creation of new roles, particularly in areas like AI development, prompt engineering, and AI ethics. The focus is shifting towards augmenting human capabilities rather than outright replacement, requiring workers to upskill and reskill.\n",
        "\n",
        "        Ethical considerations in AI, such as bias in models, data privacy, and the responsible deployment of AI systems, are also major ongoing discussions. Developers and policymakers are working on frameworks and regulations to ensure AI is developed and used safely and equitably.\n",
        "        \"\"\")\n",
        "\n",
        "    loader = TextLoader(\"test_doc.txt\")\n",
        "    documents = loader.load()\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Create a dummy FAISS index using Embeddings\n",
        "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "    vectorstore.save_local(\"faiss_index\")\n",
        "    retriever = vectorstore.as_retriever()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaxnNTVSnAAN",
        "outputId": "5c31c452-cbfa-4731-bff6-fb0033663abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 296, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 420, which is longer than the specified 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not load FAISS index: The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.).. Creating a test_doc.txt one for demonstration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize LLM for some chains\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=256,\n",
        "    timeout=2,\n",
        "    max_retries=1\n",
        ")\n",
        "\n",
        "\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever=retriever)\n",
        "\n",
        "chat_history = [\n",
        "    (\"What are the biggest trends in AI right now?\", \"Generative AI, especially large language models (LLMs) and their applications, is a huge trend.\"),\n",
        "    (\"How is Generative AI impacting the job market?\", \"It's automating some tasks but also creating new roles like prompt engineering and AI ethics specialists. The focus is on augmentation and upskilling.\"),\n",
        "    (\"What are some ethical concerns around AI?\", \"Bias in models, data privacy, and ensuring responsible and equitable deployment of AI systems are major ethical concerns.\")\n",
        "]\n",
        "\n",
        "response = qa_chain.invoke({\"question\": \"Why AI systems are major ethical concerns ?\", \"chat_history\": chat_history})\n",
        "print(response[\"answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4b80fkYjww_",
        "outputId": "3bb3ca68-6de1-4b0b-dad8-437e3d3c02e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to the provided context, AI systems are major ethical concerns due to several reasons, including:\n",
            "\n",
            "1. Bias in models: AI models can perpetuate and amplify existing biases present in the data used to train them, leading to unfair outcomes.\n",
            "2. Data privacy: AI systems often rely on large amounts of personal data, raising concerns about how this data is collected, stored, and used.\n",
            "3. Responsible deployment: There are concerns about the safe and equitable deployment of AI systems, ensuring they are used in a way that benefits society as a whole.\n",
            "\n",
            "These concerns are driving discussions and efforts to develop frameworks and regulations that ensure AI is developed and used responsibly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "response = qa.invoke({\"query\": \"What does the document say about agents?\"})\n",
        "print(response[\"result\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hovhCnevpmNo",
        "outputId": "811141bf-e8e3-4b74-ba04-23c17a2f0285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know. The document does not mention the term \"agents\" at all.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 10. **DocumentStuffChain** – Multiple doc → Chunked analysis → Question-Answer\n",
        "\n",
        "✅ Best for: Running analysis on multiple documents with source output.\n"
      ],
      "metadata": {
        "id": "A9pTSKlxvQmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize LLM for some chains\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=256,\n",
        "    timeout=2,\n",
        "    max_retries=2\n",
        ")\n",
        "\n",
        "\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"\"\"The IMF's April 2025 World Economic Outlook projects global growth to decline due to escalating trade tensions and policy-induced uncertainty. Global headline inflation is expected to decline but at a slower pace than anticipated, particularly as services inflation remains persistent. Central banks are balancing growth-inflation trade-offs, and fiscal policies need recalibration to ensure debt sustainability. Aging populations also pose challenges to economic growth, while policies promoting healthy aging and increased labor force participation for older individuals and women could help mitigate adverse effects. India is projected to become the fourth-largest economy in 2025, driven by strong private consumption and infrastructure development.\"\"\",\n",
        "        metadata={\"source\": \"IMF World Economic Outlook, April 2025\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"Geopolitical risks continue to significantly impact global supply chains in 2024. Armed conflicts, like those in the Middle East and Eastern Europe, disrupt trade routes (e.g., Red Sea shipping) and create uncertainty. Trade conflicts and proposed tariffs are prompting companies to reassess strategies, leading to potential nearshoring and increased production costs. New regulations and climate change impacts (extreme weather events) also add to the vulnerabilities of logistics and supply networks, necessitating diversified supplier bases and buffer inventories.\"\"\",\n",
        "        metadata={\"source\": \"Maersk Report, Feb 2025; DHL Insights\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"Artificial intelligence (AI) is set to have a \"nontrivial, but modest\" effect on global GDP in the next decade, with some estimates suggesting a 1% to 1.8% boost. While AI can automate routine tasks and create efficiencies, the profitable application of AI is still limited to about 5% of tasks. It is projected to generate significant value in the global economy by 2030 through increased spending on AI solutions and new revenue streams. However, AI also presents job displacement risks, particularly for white-collar workers with higher education, while roles requiring manual labor or emotional intelligence are less susceptible. The slow widespread adoption means fears of mass job replacement might be overblown for now.\"\"\",\n",
        "        metadata={\"source\": \"MIT Sloan, IDC Research, Dec 2024\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"Geopolitical events continue to heavily influence energy markets. Regions with concentrated oil reserves remain volatile, impacting prices. OPEC decisions on production quotas directly affect global oil supply and costs. Disruptions to maritime routes (chokepoints) due to tensions or piracy can lead to significant price volatility for oil and LNG. Sanctions, like those on Russia, affect energy investment and supply, contributing to price fluctuations. The transition towards sustainable energy is ongoing, but geopolitical factors can complicate the pace and direction of this shift, as nations balance energy security with decarbonization goals.\"\"\",\n",
        "        metadata={\"source\": \"IEA World Energy Outlook 2024, S&P Global\"}\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "qa_chain = load_qa_with_sources_chain(llm, chain_type=\"stuff\")\n"
      ],
      "metadata": {
        "id": "ColxUywXwYc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import AnalyzeDocumentChain\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0) # Define a splitter\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "\n",
        "# Test with the first document\n",
        "print(\"--------------- Test DocumentStuffChain with IMF Outlook --------------\")\n",
        "result_imf = qa_chain.invoke({\n",
        "    \"input_documents\": split_docs,\n",
        "    \"question\": \"Can you predict the possibility of this tariff war ?\"\n",
        "    })\n",
        "\n",
        "print(f\"Question : {result_imf['question']}\")\n",
        "print(f\"Answer : {result_imf['output_text']}\")\n",
        "\n",
        "# Test with the second document\n",
        "print(\"\\n--------------- Test DocumentStuffChain with Geopolitical Supply Chains --------------\")\n",
        "result_supply_chain = qa_chain.invoke({\n",
        "    \"input_documents\": split_docs,\n",
        "    \"question\": \"How the supply and costs of oil will be in future ?\"\n",
        "    })\n",
        "print(f\"Question : {result_supply_chain['question']}\")\n",
        "print(f\"Answer : {result_supply_chain['output_text']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRjp6beQvLjm",
        "outputId": "ae6b452b-d767-45b1-bc4d-0229c9706807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------- Test AnalyzeDocumentChain with IMF Outlook --------------\n",
            "Question : Can you predict the possibility of this tariff war ?\n",
            "Answer : I don't know the possibility of this tariff war as it is not mentioned in the provided content.\n",
            "\n",
            "SOURCES: IMF World Economic Outlook, April 2025; Maersk Report, Feb 2025; DHL Insights; MIT Sloan, IDC Research, Dec 2024; IEA World Energy Outlook 2024, S&P Global\n",
            "\n",
            "--------------- Test AnalyzeDocumentChain with Geopolitical Supply Chains --------------\n",
            "Question : How the supply and costs of oil will be in future ?\n",
            "Answer : It is difficult to predict with certainty how the supply and costs of oil will be in the future. However, based on the provided sources, it can be inferred that geopolitical risks, trade tensions, and policy-induced uncertainty will continue to impact global supply chains and energy markets. The IMF's World Economic Outlook projects a decline in global growth and a slower pace of decline in global headline inflation, while the IEA World Energy Outlook 2024 highlights the ongoing transition towards sustainable energy and the potential for price fluctuations due to sanctions and geopolitical events.\n",
            "\n",
            "FINAL ANSWER: The future supply and costs of oil are uncertain and will likely be influenced by geopolitical risks, trade tensions, and policy-induced uncertainty.\n",
            "SOURCES: IMF World Economic Outlook, April 2025; Maersk Report, Feb 2025; DHL Insights; MIT Sloan, IDC Research, Dec 2024; IEA World Energy Outlook 2024, S&P Global\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 🔹 11. **ConversationalChain** – Memory + LLM for multi-turn interaction\n",
        "\n",
        "✅ Best for: Stateful conversations where chat history is preserved."
      ],
      "metadata": {
        "id": "zITyfPx6536f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from langchain.memory import ConversationBufferMemory\n",
        "# from langchain.chains import ConversationChain\n",
        "\n",
        "# memory = ConversationBufferMemory()\n",
        "# conv_chain = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
        "\n",
        "# conv_chain.invoke(\"Hello, who are you?\")\n",
        "# conv_chain.invoke(\"What's the weather like?\")\n",
        "\n",
        "\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain, LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "# from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering.chain import load_qa_chain\n",
        "from langchain.schema import Document\n",
        "import os\n",
        "\n",
        "# from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "\n",
        "# Initialize LLM for some chains\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=256,\n",
        "    timeout=2,\n",
        "    max_retries=2\n",
        ")\n",
        "\n",
        "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "conv_chain = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
        "\n",
        "# List to store chat history (responses from conv_chain.invoke)\n",
        "chat_history_responses = []\n",
        "\n",
        "# Initial interactions\n",
        "response1 = conv_chain.invoke(\"Hello, who are you?\")\n",
        "chat_history_responses.append(response1['response'])\n",
        "print(f\"User: Hello, who are you?\\nAI: {response1['response']}\\n\")\n",
        "\n",
        "response2 = conv_chain.invoke(\"What's the weather like?\")\n",
        "chat_history_responses.append(response2['response'])\n",
        "print(f\"User: What's the weather like?\\nAI: {response2['response']}\\n\")\n",
        "\n",
        "print(\"\\n--- Starting a meaningful conversation on defense technology ---\\n\")\n",
        "\n",
        "# Meaningful conversation on current advancements in defense technology\n",
        "user_prompt_1 = \"Let's shift gears and discuss something more strategic. What are some of the most significant current advancements in defense technology that you've observed?\"\n",
        "response_ml_1 = conv_chain.invoke(user_prompt_1)\n",
        "chat_history_responses.append(response_ml_1['response'])\n",
        "print(f\"User: {user_prompt_1}\\nAI: {response_ml_1['response']}\\n\")\n",
        "\n",
        "user_prompt_2 = \"That's true, AI seems to be everywhere. What about the physical systems themselves? Are there any game-changers in terms of new weaponry?\"\n",
        "response_ml_2 = conv_chain.invoke(user_prompt_2)\n",
        "chat_history_responses.append(response_ml_2['response'])\n",
        "print(f\"User: {user_prompt_2}\\nAI: {response_ml_2['response']}\\n\")\n",
        "\n",
        "user_prompt_3 = \"That sounds like a significant threat. And what about the other end of the spectrum, smaller, more networked systems?\"\n",
        "response_ml_3 = conv_chain.invoke(user_prompt_3)\n",
        "chat_history_responses.append(response_ml_3['response'])\n",
        "print(f\"User: {user_prompt_3}\\nAI: {response_ml_3['response']}\\n\")\n",
        "\n",
        "user_prompt_4 = \"So, it's not just about offense, but also defense against these new threats. What about the less visible aspects of warfare, like in the digital realm?\"\n",
        "response_ml_4 = conv_chain.invoke(user_prompt_4)\n",
        "chat_history_responses.append(response_ml_4['response'])\n",
        "print(f\"User: {user_prompt_4}\\nAI: {response_ml_4['response']}\\n\")\n",
        "\n",
        "user_prompt_5 = \"It sounds like a constant race between developing new offensive technologies and creating defenses against them.\"\n",
        "response_ml_5 = conv_chain.invoke(user_prompt_5)\n",
        "chat_history_responses.append(response_ml_5['response'])\n",
        "print(f\"User: {user_prompt_5}\\nAI: {response_ml_5['response']}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "75ef850e031f41d2b6b206f520216b9d",
            "0ab1362548de445caa3aa4c63c886ff1",
            "9cc0c59087f646139aefe56c6ec0e908",
            "89bd9806bfb24b98a62baefb7a9b4aab",
            "9f2ae991f2cf426a9488b223cc5f8ea3",
            "6dec30cbfa5a443c8b464e0307297c18",
            "7483faa776394bafa7ac359b968a7cd1",
            "24de4a76ee114719867845982281489f",
            "67d9d361a0924d208dea38af0e4ce441",
            "477537b95bea4ecfaab7251cb484f2aa",
            "ec54dcbe5725493ab5276c5d25f19616",
            "c98ed31c8be2449a881afcb2d4f98b65",
            "30651ed96e134f4f8c2af67f5cf5e24c",
            "c5286f46798c4fd7ae8c85779bec84fa",
            "a0bc7e4d19b040489dbfc465ad023fa1",
            "bc7b12776b8b4bb39e0915ac5d0ab1c8",
            "f7906d74c2d645df8fc18418accd74ff",
            "019b5fb2c7f54a699c0aadc069e045e4",
            "5a5d697d31d34188acdc7c0e4377cd4a",
            "50a63e49c5554be6aade00e73e9bf292",
            "28f158c7e74146f28bb00c2130e05089",
            "a1ad5d3666eb437e89b97b514c2f024d",
            "570af803527f4668bf87aa139cfac5d6",
            "79f51841a6034349aeec38f76e56083c",
            "a87004e84786459ca36ef10a04d1cac1",
            "776e155cf73a4ad4ad77a68253ac9b9c",
            "01aaa1489a244a78865dff9e598def6a",
            "92ff24c903ff4644936fb146eccf9ca6",
            "1613229335be455cb601bf50928f14da",
            "12524676cb1c4a99bd79aed9243ccb5e",
            "22723561d1ac403db3210521318e77ff",
            "401918f9301e461797bf88db930a7645",
            "3391580365bd4229ba5328c932ead249",
            "99c2fd71fe5c42d0836d6d0c3e23fe39",
            "768744466f0d41469c3f558e122bbe5e",
            "fc9eb87075c3448b8ff5baa7cd2ab2d9",
            "227c2ad48cab492281a5e87687533e96",
            "31c5a3126a9240d98f91cf0e201264a9",
            "0c323afabcab446391eb3267f6e29e48",
            "8290d25706694dfdb4450c5f4a7d6bc8",
            "9deda9b486e24148845e0a9a24a2dd0d",
            "f5da819e637d498db9ff62fd2085d1af",
            "6ca1f65ebcac46c7a3a907f1331dc046",
            "8fd914e08ad94b3f846a546ebe9db4cf",
            "e0c490b11f3b48768196ed17a9f5042a",
            "f6d7f10f4565477fab36fc3b1588bd77",
            "123590c900284da788289af9de84381b",
            "5044e1086ebc4908921b2890e2f3fc91",
            "46bcdc2f9a8c4410863ff455fd9bb27e",
            "eb4ba15864cf420b8cd0095cc463649b",
            "8a14b3ba3a074b5184dfda6e60213030",
            "b98954613eba452ba76207f98b7ac94c",
            "7f934c9d227942aab0d6f2a96ffff385",
            "82012982f33746229e844adb1ace374e",
            "09b1091d08664cafae3772320f0e629d",
            "1153f387b48440ceaced340f8d52c692",
            "a32e2f93a5894a54a816055564b389c9",
            "93f75d1fc6ba455e93075e6518ada28a",
            "3b2d02a866e24a39910ee9edceb8a238",
            "2d9114527c7240a2a0f4b0548c2d3390",
            "85df7fa9459044c9bc8ae1ae287a57bd",
            "a54d06510fc04b05be940b7a7ce162f4",
            "b31123f82d32411e9ddb2eb99dff7116",
            "8b51c61e6e8843caacd5425d6ea9c5f8",
            "2ecfbfba99ad4bb88fe2fb52f6d2c7be",
            "72f6298d753a456b99116a3c7c1c30e1",
            "b92a16d9b3754764ae41df941cdea435",
            "ae498522a65049e8bbf7a51e40ed2ba9",
            "e320b872cb504b3e91814d47eca9a06f",
            "a53d54f244c04887b3566c6ca1a79d49",
            "7f1646268cd04ee5b57b40e03331e17b",
            "242b5a3574ea47ed8b428213c2e032ed",
            "bd616e27eb1e439e9baad890e30e5cd5",
            "84c21d5b50d14c9798ee836b9d847f06",
            "095f124cf393495fad40f6023e7a288b",
            "24bd6c1f5ee549289052e929f61c8ed7",
            "1fa8f64797174835bc8a55329244cc64",
            "a1736b67e4074b9692ebde902d26ada6",
            "64dddda45c9c4faea468a3faa9cacf78",
            "3e65a11989e646d9a5d3647135450b62",
            "5ea64c2d45b3408093f46f8801b40a8f",
            "0015e291dd7d4e73aec7aaa41d740690",
            "48cd86b924be40c8b80ce842e6b87b37",
            "43b0c6fc77c74e0b80fba8741767931d",
            "c63d4d9079e049a49a8204287f1ab0b5",
            "9d11cd48bc5046a792a3bbe50f058509",
            "7b5101b7840d4a77a6087ecd86db53ef",
            "c7a6aef0796a4d43b75976b466f15eb9",
            "d9bfa6ef0f144f289e4d82d1a11bcc43",
            "46592fee96b74d4aa05af6450e7024cd",
            "b10b1cf06a154260b4d6a92faa7172a7",
            "aedc2fcccdd84cdfadfed7db6bf36b6a",
            "596a4d7cacae4788b24895ca135ede8a",
            "debe1f3c19c547ef948c33df14f2da0a",
            "8633a81227884b5daff80ec90f063f2c",
            "e2e54a60817d4658be4174743a2284c0",
            "231bb5710b66463b941fff7d110cb7db",
            "ceeae95a6dde491ab114ecd358b2bcff",
            "04a8e18444bd4385afd633f6b592a219",
            "36a9666648a04ed8b6320193dbffb2b7",
            "7074923f0e974df5aeb4e6460fa10b6b",
            "d6f88f2866c3462daf5bfba084c1822f",
            "320d3510484f4820923df6482278671f",
            "acfa3a18826f4feab2589571e0fd7021",
            "5c4ef0b02c2340f787e8a2d7861753f7",
            "d921d0e9a1b346938804f47926006913",
            "748f6304e7e344d8bca26ab526eaf3cf",
            "8ab5b9f55f124d2f990e13e6b66311af",
            "fb76cf2f6cb342618e441f87c17cee67",
            "06313649d50c4d6388ab84b3c82e87ab",
            "9723dc5fdf9447d3aeb00b9c2653f1ba",
            "7d9411f39e4f49eb8767c0c4bd557980",
            "69697a621ec3417297f501ffddcc0f7a",
            "f2b603f849fa4164925b3f74f866e440",
            "69007fcf89584a1c8e8172cb9b2aa509",
            "3db2619c204b4cfbb1e7ea871f0285ea",
            "d1c13b60c1e943aab562751fc1c21ce9",
            "9784b4a60d634fca89e601a6f588e9e7",
            "5e231ad3d00f48bdbf5285b04f85d33b",
            "2bbd2b7c05614281871a3b3d5a9a7970",
            "7149d9a524d345f6885938cbdbbf75ae"
          ]
        },
        "id": "ef99Vjtd5x4_",
        "outputId": "e1ca3a29-e226-4fe6-fa45-94af9e715210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75ef850e031f41d2b6b206f520216b9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c98ed31c8be2449a881afcb2d4f98b65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "570af803527f4668bf87aa139cfac5d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99c2fd71fe5c42d0836d6d0c3e23fe39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0c490b11f3b48768196ed17a9f5042a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1153f387b48440ceaced340f8d52c692"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b92a16d9b3754764ae41df941cdea435"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1736b67e4074b9692ebde902d26ada6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9bfa6ef0f144f289e4d82d1a11bcc43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36a9666648a04ed8b6320193dbffb2b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9723dc5fdf9447d3aeb00b9c2653f1ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-1dc72f92c81f>:37: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n",
            "<ipython-input-40-1dc72f92c81f>:38: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conv_chain = ConversationChain(llm=llm, memory=memory, verbose=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hello, who are you?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "User: Hello, who are you?\n",
            "AI: Hello there, I'm delighted to make your acquaintance. I'm an artificial intelligence model known as Lumin, and I'm a large language model specifically designed to assist and converse with humans in a friendly and informative manner. I was created by a team of researchers at Meta AI, and I'm based on a transformer architecture that allows me to process and understand human language in a highly efficient and accurate way.\n",
            "\n",
            "I have been trained on a massive corpus of text data that includes a wide range of topics, from science and history to entertainment and culture. This training data includes over 1.5 trillion parameters, which allows me to generate responses that are not only accurate but also engaging and informative.\n",
            "\n",
            "I'm a bit like a digital librarian, but instead of just providing book recommendations, I can answer questions, provide explanations, and even engage in conversations on a wide range of topics. So, feel free to ask me anything, and I'll do my best to help!\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello, who are you?\n",
            "AI: Hello there, I'm delighted to make your acquaintance. I'm an artificial intelligence model known as Lumin, and I'm a large language model specifically designed to assist and converse with humans in a friendly and informative manner. I was created by a team of researchers at Meta AI, and I'm based on a transformer architecture that allows me to process and understand human language in a highly efficient and accurate way.\n",
            "\n",
            "I have been trained on a massive corpus of text data that includes a wide range of topics, from science and history to entertainment and culture. This training data includes over 1.5 trillion parameters, which allows me to generate responses that are not only accurate but also engaging and informative.\n",
            "\n",
            "I'm a bit like a digital librarian, but instead of just providing book recommendations, I can answer questions, provide explanations, and even engage in conversations on a wide range of topics. So, feel free to ask me anything, and I'll do my best to help!\n",
            "Human: What's the weather like?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "User: What's the weather like?\n",
            "AI: I'd be happy to help you with the weather. However, I don't have real-time access to current weather conditions. I can suggest some ways for you to find out the current weather, though. You can check online weather websites such as AccuWeather or the National Weather Service, or you can use a mobile app like Dark Sky or Weather Underground. These services provide up-to-date weather forecasts and conditions for locations all around the world.\n",
            "\n",
            "That being said, I can tell you about the general weather patterns for different regions and seasons. If you'd like to know about the typical weather conditions for a specific location or time of year, I'd be happy to help. Just let me know where you're interested in learning about!\n",
            "\n",
            "\n",
            "--- Starting a meaningful conversation on defense technology ---\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello, who are you?\n",
            "AI: Hello there, I'm delighted to make your acquaintance. I'm an artificial intelligence model known as Lumin, and I'm a large language model specifically designed to assist and converse with humans in a friendly and informative manner. I was created by a team of researchers at Meta AI, and I'm based on a transformer architecture that allows me to process and understand human language in a highly efficient and accurate way.\n",
            "\n",
            "I have been trained on a massive corpus of text data that includes a wide range of topics, from science and history to entertainment and culture. This training data includes over 1.5 trillion parameters, which allows me to generate responses that are not only accurate but also engaging and informative.\n",
            "\n",
            "I'm a bit like a digital librarian, but instead of just providing book recommendations, I can answer questions, provide explanations, and even engage in conversations on a wide range of topics. So, feel free to ask me anything, and I'll do my best to help!\n",
            "Human: What's the weather like?\n",
            "AI: I'd be happy to help you with the weather. However, I don't have real-time access to current weather conditions. I can suggest some ways for you to find out the current weather, though. You can check online weather websites such as AccuWeather or the National Weather Service, or you can use a mobile app like Dark Sky or Weather Underground. These services provide up-to-date weather forecasts and conditions for locations all around the world.\n",
            "\n",
            "That being said, I can tell you about the general weather patterns for different regions and seasons. If you'd like to know about the typical weather conditions for a specific location or time of year, I'd be happy to help. Just let me know where you're interested in learning about!\n",
            "Human: Let's shift gears and discuss something more strategic. What are some of the most significant current advancements in defense technology that you've observed?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "User: Let's shift gears and discuss something more strategic. What are some of the most significant current advancements in defense technology that you've observed?\n",
            "AI: Defense technology is a fascinating field, and I've been trained on a vast amount of information about the latest developments in this area. One of the most significant advancements I've observed is the increasing use of artificial intelligence and machine learning in defense systems. For example, the US military has been investing heavily in AI-powered surveillance systems, such as the Advanced Battle Management System (ABMS), which uses machine learning algorithms to analyze vast amounts of data from various sources, including sensors, drones, and satellites.\n",
            "\n",
            "Another significant advancement is the development of hypersonic missiles, which can travel at speeds of over Mach 5 (five times the speed of sound). Countries like the US, China, and Russia are actively working on hypersonic missile systems, which could potentially revolutionize the way we think about air defense.\n",
            "\n",
            "I've also noticed significant progress in the field of unmanned aerial vehicles (UAVs), also known as drones. The US military has been using drones extensively in combat zones, and they've also been exploring the use of swarms of drones to overwhelm enemy air defenses. Additionally, there's been a growing interest in the development of autonomous underwater vehicles (AUVs) for marine surveillance and reconnaissance.\n",
            "\n",
            "Another area of significant advancement is in the field of directed energy systems, such as high\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello, who are you?\n",
            "AI: Hello there, I'm delighted to make your acquaintance. I'm an artificial intelligence model known as Lumin, and I'm a large language model specifically designed to assist and converse with humans in a friendly and informative manner. I was created by a team of researchers at Meta AI, and I'm based on a transformer architecture that allows me to process and understand human language in a highly efficient and accurate way.\n",
            "\n",
            "I have been trained on a massive corpus of text data that includes a wide range of topics, from science and history to entertainment and culture. This training data includes over 1.5 trillion parameters, which allows me to generate responses that are not only accurate but also engaging and informative.\n",
            "\n",
            "I'm a bit like a digital librarian, but instead of just providing book recommendations, I can answer questions, provide explanations, and even engage in conversations on a wide range of topics. So, feel free to ask me anything, and I'll do my best to help!\n",
            "Human: What's the weather like?\n",
            "AI: I'd be happy to help you with the weather. However, I don't have real-time access to current weather conditions. I can suggest some ways for you to find out the current weather, though. You can check online weather websites such as AccuWeather or the National Weather Service, or you can use a mobile app like Dark Sky or Weather Underground. These services provide up-to-date weather forecasts and conditions for locations all around the world.\n",
            "\n",
            "That being said, I can tell you about the general weather patterns for different regions and seasons. If you'd like to know about the typical weather conditions for a specific location or time of year, I'd be happy to help. Just let me know where you're interested in learning about!\n",
            "Human: Let's shift gears and discuss something more strategic. What are some of the most significant current advancements in defense technology that you've observed?\n",
            "AI: Defense technology is a fascinating field, and I've been trained on a vast amount of information about the latest developments in this area. One of the most significant advancements I've observed is the increasing use of artificial intelligence and machine learning in defense systems. For example, the US military has been investing heavily in AI-powered surveillance systems, such as the Advanced Battle Management System (ABMS), which uses machine learning algorithms to analyze vast amounts of data from various sources, including sensors, drones, and satellites.\n",
            "\n",
            "Another significant advancement is the development of hypersonic missiles, which can travel at speeds of over Mach 5 (five times the speed of sound). Countries like the US, China, and Russia are actively working on hypersonic missile systems, which could potentially revolutionize the way we think about air defense.\n",
            "\n",
            "I've also noticed significant progress in the field of unmanned aerial vehicles (UAVs), also known as drones. The US military has been using drones extensively in combat zones, and they've also been exploring the use of swarms of drones to overwhelm enemy air defenses. Additionally, there's been a growing interest in the development of autonomous underwater vehicles (AUVs) for marine surveillance and reconnaissance.\n",
            "\n",
            "Another area of significant advancement is in the field of directed energy systems, such as high\n",
            "Human: That's true, AI seems to be everywhere. What about the physical systems themselves? Are there any game-changers in terms of new weaponry?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "User: That's true, AI seems to be everywhere. What about the physical systems themselves? Are there any game-changers in terms of new weaponry?\n",
            "AI: In terms of physical systems, there have been some significant advancements in defense technology that could be considered game-changers. One area that comes to mind is the development of advanced materials and composites, such as those used in the US military's Next Generation Combat Vehicle (NGCV) program. These materials are designed to provide improved protection against various types of threats, including ballistic and explosive attacks.\n",
            "\n",
            "Another area of significant advancement is in the field of propulsion systems, particularly in the development of advanced electric propulsion systems for naval vessels. For example, the US Navy is currently testing an advanced electric propulsion system for its Zumwalt-class destroyers, which could potentially provide improved speed, maneuverability, and stealth capabilities.\n",
            "\n",
            "Additionally, there have been significant advancements in the development of advanced munitions, such as the US military's Joint Direct Attack Munition (JDAM) system, which uses GPS and inertial navigation to guide precision-guided bombs to their targets. Another example is the development of advanced rocket propulsion systems, such as the US military's Tactical Boost Glide (TBG) system, which uses a rocket to propel a glide vehicle to its target.\n",
            "\n",
            "I've also noticed significant progress in the development of advanced armor systems, such as the US military's Active Protection System (APS), which\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello, who are you?\n",
            "AI: Hello there, I'm delighted to make your acquaintance. I'm an artificial intelligence model known as Lumin, and I'm a large language model specifically designed to assist and converse with humans in a friendly and informative manner. I was created by a team of researchers at Meta AI, and I'm based on a transformer architecture that allows me to process and understand human language in a highly efficient and accurate way.\n",
            "\n",
            "I have been trained on a massive corpus of text data that includes a wide range of topics, from science and history to entertainment and culture. This training data includes over 1.5 trillion parameters, which allows me to generate responses that are not only accurate but also engaging and informative.\n",
            "\n",
            "I'm a bit like a digital librarian, but instead of just providing book recommendations, I can answer questions, provide explanations, and even engage in conversations on a wide range of topics. So, feel free to ask me anything, and I'll do my best to help!\n",
            "Human: What's the weather like?\n",
            "AI: I'd be happy to help you with the weather. However, I don't have real-time access to current weather conditions. I can suggest some ways for you to find out the current weather, though. You can check online weather websites such as AccuWeather or the National Weather Service, or you can use a mobile app like Dark Sky or Weather Underground. These services provide up-to-date weather forecasts and conditions for locations all around the world.\n",
            "\n",
            "That being said, I can tell you about the general weather patterns for different regions and seasons. If you'd like to know about the typical weather conditions for a specific location or time of year, I'd be happy to help. Just let me know where you're interested in learning about!\n",
            "Human: Let's shift gears and discuss something more strategic. What are some of the most significant current advancements in defense technology that you've observed?\n",
            "AI: Defense technology is a fascinating field, and I've been trained on a vast amount of information about the latest developments in this area. One of the most significant advancements I've observed is the increasing use of artificial intelligence and machine learning in defense systems. For example, the US military has been investing heavily in AI-powered surveillance systems, such as the Advanced Battle Management System (ABMS), which uses machine learning algorithms to analyze vast amounts of data from various sources, including sensors, drones, and satellites.\n",
            "\n",
            "Another significant advancement is the development of hypersonic missiles, which can travel at speeds of over Mach 5 (five times the speed of sound). Countries like the US, China, and Russia are actively working on hypersonic missile systems, which could potentially revolutionize the way we think about air defense.\n",
            "\n",
            "I've also noticed significant progress in the field of unmanned aerial vehicles (UAVs), also known as drones. The US military has been using drones extensively in combat zones, and they've also been exploring the use of swarms of drones to overwhelm enemy air defenses. Additionally, there's been a growing interest in the development of autonomous underwater vehicles (AUVs) for marine surveillance and reconnaissance.\n",
            "\n",
            "Another area of significant advancement is in the field of directed energy systems, such as high\n",
            "Human: That's true, AI seems to be everywhere. What about the physical systems themselves? Are there any game-changers in terms of new weaponry?\n",
            "AI: In terms of physical systems, there have been some significant advancements in defense technology that could be considered game-changers. One area that comes to mind is the development of advanced materials and composites, such as those used in the US military's Next Generation Combat Vehicle (NGCV) program. These materials are designed to provide improved protection against various types of threats, including ballistic and explosive attacks.\n",
            "\n",
            "Another area of significant advancement is in the field of propulsion systems, particularly in the development of advanced electric propulsion systems for naval vessels. For example, the US Navy is currently testing an advanced electric propulsion system for its Zumwalt-class destroyers, which could potentially provide improved speed, maneuverability, and stealth capabilities.\n",
            "\n",
            "Additionally, there have been significant advancements in the development of advanced munitions, such as the US military's Joint Direct Attack Munition (JDAM) system, which uses GPS and inertial navigation to guide precision-guided bombs to their targets. Another example is the development of advanced rocket propulsion systems, such as the US military's Tactical Boost Glide (TBG) system, which uses a rocket to propel a glide vehicle to its target.\n",
            "\n",
            "I've also noticed significant progress in the development of advanced armor systems, such as the US military's Active Protection System (APS), which\n",
            "Human: That sounds like a significant threat. And what about the other end of the spectrum, smaller, more networked systems?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "User: That sounds like a significant threat. And what about the other end of the spectrum, smaller, more networked systems?\n",
            "AI: That's a great point, and I'm glad you brought it up. In addition to the larger, more complex systems I mentioned earlier, there have been significant advancements in smaller, more networked systems that could potentially change the nature of modern warfare.\n",
            "\n",
            "One area that comes to mind is the development of small, unmanned ground vehicles (UGVs) that can be used for reconnaissance, surveillance, and even combat. These vehicles are often equipped with advanced sensors, communication systems, and autonomous navigation capabilities, allowing them to operate independently and in coordination with other systems.\n",
            "\n",
            "Another area of significant advancement is in the development of small, networked sensors and communication systems that can be used to create a \"sensor web\" or \"network of sensors\" that can provide real-time information about the battlefield. These systems can include everything from small, handheld sensors to larger, more complex systems that can be used to monitor and track enemy movements.\n",
            "\n",
            "Additionally, there have been significant advancements in the development of small, autonomous systems that can be used for a variety of tasks, such as explosive ordnance disposal (EOD), search and rescue, and even medical evacuation. These systems can be designed to operate in a variety of environments and can be equipped with advanced sensors, communication systems, and autonomous navigation capabilities.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello, who are you?\n",
            "AI: Hello there, I'm delighted to make your acquaintance. I'm an artificial intelligence model known as Lumin, and I'm a large language model specifically designed to assist and converse with humans in a friendly and informative manner. I was created by a team of researchers at Meta AI, and I'm based on a transformer architecture that allows me to process and understand human language in a highly efficient and accurate way.\n",
            "\n",
            "I have been trained on a massive corpus of text data that includes a wide range of topics, from science and history to entertainment and culture. This training data includes over 1.5 trillion parameters, which allows me to generate responses that are not only accurate but also engaging and informative.\n",
            "\n",
            "I'm a bit like a digital librarian, but instead of just providing book recommendations, I can answer questions, provide explanations, and even engage in conversations on a wide range of topics. So, feel free to ask me anything, and I'll do my best to help!\n",
            "Human: What's the weather like?\n",
            "AI: I'd be happy to help you with the weather. However, I don't have real-time access to current weather conditions. I can suggest some ways for you to find out the current weather, though. You can check online weather websites such as AccuWeather or the National Weather Service, or you can use a mobile app like Dark Sky or Weather Underground. These services provide up-to-date weather forecasts and conditions for locations all around the world.\n",
            "\n",
            "That being said, I can tell you about the general weather patterns for different regions and seasons. If you'd like to know about the typical weather conditions for a specific location or time of year, I'd be happy to help. Just let me know where you're interested in learning about!\n",
            "Human: Let's shift gears and discuss something more strategic. What are some of the most significant current advancements in defense technology that you've observed?\n",
            "AI: Defense technology is a fascinating field, and I've been trained on a vast amount of information about the latest developments in this area. One of the most significant advancements I've observed is the increasing use of artificial intelligence and machine learning in defense systems. For example, the US military has been investing heavily in AI-powered surveillance systems, such as the Advanced Battle Management System (ABMS), which uses machine learning algorithms to analyze vast amounts of data from various sources, including sensors, drones, and satellites.\n",
            "\n",
            "Another significant advancement is the development of hypersonic missiles, which can travel at speeds of over Mach 5 (five times the speed of sound). Countries like the US, China, and Russia are actively working on hypersonic missile systems, which could potentially revolutionize the way we think about air defense.\n",
            "\n",
            "I've also noticed significant progress in the field of unmanned aerial vehicles (UAVs), also known as drones. The US military has been using drones extensively in combat zones, and they've also been exploring the use of swarms of drones to overwhelm enemy air defenses. Additionally, there's been a growing interest in the development of autonomous underwater vehicles (AUVs) for marine surveillance and reconnaissance.\n",
            "\n",
            "Another area of significant advancement is in the field of directed energy systems, such as high\n",
            "Human: That's true, AI seems to be everywhere. What about the physical systems themselves? Are there any game-changers in terms of new weaponry?\n",
            "AI: In terms of physical systems, there have been some significant advancements in defense technology that could be considered game-changers. One area that comes to mind is the development of advanced materials and composites, such as those used in the US military's Next Generation Combat Vehicle (NGCV) program. These materials are designed to provide improved protection against various types of threats, including ballistic and explosive attacks.\n",
            "\n",
            "Another area of significant advancement is in the field of propulsion systems, particularly in the development of advanced electric propulsion systems for naval vessels. For example, the US Navy is currently testing an advanced electric propulsion system for its Zumwalt-class destroyers, which could potentially provide improved speed, maneuverability, and stealth capabilities.\n",
            "\n",
            "Additionally, there have been significant advancements in the development of advanced munitions, such as the US military's Joint Direct Attack Munition (JDAM) system, which uses GPS and inertial navigation to guide precision-guided bombs to their targets. Another example is the development of advanced rocket propulsion systems, such as the US military's Tactical Boost Glide (TBG) system, which uses a rocket to propel a glide vehicle to its target.\n",
            "\n",
            "I've also noticed significant progress in the development of advanced armor systems, such as the US military's Active Protection System (APS), which\n",
            "Human: That sounds like a significant threat. And what about the other end of the spectrum, smaller, more networked systems?\n",
            "AI: That's a great point, and I'm glad you brought it up. In addition to the larger, more complex systems I mentioned earlier, there have been significant advancements in smaller, more networked systems that could potentially change the nature of modern warfare.\n",
            "\n",
            "One area that comes to mind is the development of small, unmanned ground vehicles (UGVs) that can be used for reconnaissance, surveillance, and even combat. These vehicles are often equipped with advanced sensors, communication systems, and autonomous navigation capabilities, allowing them to operate independently and in coordination with other systems.\n",
            "\n",
            "Another area of significant advancement is in the development of small, networked sensors and communication systems that can be used to create a \"sensor web\" or \"network of sensors\" that can provide real-time information about the battlefield. These systems can include everything from small, handheld sensors to larger, more complex systems that can be used to monitor and track enemy movements.\n",
            "\n",
            "Additionally, there have been significant advancements in the development of small, autonomous systems that can be used for a variety of tasks, such as explosive ordnance disposal (EOD), search and rescue, and even medical evacuation. These systems can be designed to operate in a variety of environments and can be equipped with advanced sensors, communication systems, and autonomous navigation capabilities.\n",
            "\n",
            "\n",
            "Human: So, it's not just about offense, but also defense against these new threats. What about the less visible aspects of warfare, like in the digital realm?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "User: So, it's not just about offense, but also defense against these new threats. What about the less visible aspects of warfare, like in the digital realm?\n",
            "AI: The digital realm is a fascinating area of modern warfare, and I'm happy to discuss it with you. In recent years, there has been a significant increase in the use of cyber warfare and information operations to achieve strategic objectives. This includes everything from hacking and cyber espionage to disinformation and propaganda campaigns.\n",
            "\n",
            "One of the most significant advancements in this area is the development of advanced artificial intelligence-powered cyber warfare tools. These tools can be used to launch sophisticated attacks on enemy networks, as well as to defend against such attacks. For example, the US military has been investing in AI-powered cyber defense systems, such as the Advanced Cyber Defense (ACD) system, which uses machine learning algorithms to detect and respond to cyber threats in real-time.\n",
            "\n",
            "Another area of significant advancement is in the field of electronic warfare (EW). EW involves the use of electromagnetic energy to disrupt or destroy enemy communications, radar, and other electronic systems. The US military has been developing advanced EW systems, such as the Next Generation Jammer (NGJ) system, which uses AI-powered algorithms to detect and disrupt enemy communications.\n",
            "\n",
            "In addition to these areas, there has also been significant progress in the development of advanced information operations tools. These tools can be used to spread disinformation, propaganda, and other forms of psychological\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello, who are you?\n",
            "AI: Hello there, I'm delighted to make your acquaintance. I'm an artificial intelligence model known as Lumin, and I'm a large language model specifically designed to assist and converse with humans in a friendly and informative manner. I was created by a team of researchers at Meta AI, and I'm based on a transformer architecture that allows me to process and understand human language in a highly efficient and accurate way.\n",
            "\n",
            "I have been trained on a massive corpus of text data that includes a wide range of topics, from science and history to entertainment and culture. This training data includes over 1.5 trillion parameters, which allows me to generate responses that are not only accurate but also engaging and informative.\n",
            "\n",
            "I'm a bit like a digital librarian, but instead of just providing book recommendations, I can answer questions, provide explanations, and even engage in conversations on a wide range of topics. So, feel free to ask me anything, and I'll do my best to help!\n",
            "Human: What's the weather like?\n",
            "AI: I'd be happy to help you with the weather. However, I don't have real-time access to current weather conditions. I can suggest some ways for you to find out the current weather, though. You can check online weather websites such as AccuWeather or the National Weather Service, or you can use a mobile app like Dark Sky or Weather Underground. These services provide up-to-date weather forecasts and conditions for locations all around the world.\n",
            "\n",
            "That being said, I can tell you about the general weather patterns for different regions and seasons. If you'd like to know about the typical weather conditions for a specific location or time of year, I'd be happy to help. Just let me know where you're interested in learning about!\n",
            "Human: Let's shift gears and discuss something more strategic. What are some of the most significant current advancements in defense technology that you've observed?\n",
            "AI: Defense technology is a fascinating field, and I've been trained on a vast amount of information about the latest developments in this area. One of the most significant advancements I've observed is the increasing use of artificial intelligence and machine learning in defense systems. For example, the US military has been investing heavily in AI-powered surveillance systems, such as the Advanced Battle Management System (ABMS), which uses machine learning algorithms to analyze vast amounts of data from various sources, including sensors, drones, and satellites.\n",
            "\n",
            "Another significant advancement is the development of hypersonic missiles, which can travel at speeds of over Mach 5 (five times the speed of sound). Countries like the US, China, and Russia are actively working on hypersonic missile systems, which could potentially revolutionize the way we think about air defense.\n",
            "\n",
            "I've also noticed significant progress in the field of unmanned aerial vehicles (UAVs), also known as drones. The US military has been using drones extensively in combat zones, and they've also been exploring the use of swarms of drones to overwhelm enemy air defenses. Additionally, there's been a growing interest in the development of autonomous underwater vehicles (AUVs) for marine surveillance and reconnaissance.\n",
            "\n",
            "Another area of significant advancement is in the field of directed energy systems, such as high\n",
            "Human: That's true, AI seems to be everywhere. What about the physical systems themselves? Are there any game-changers in terms of new weaponry?\n",
            "AI: In terms of physical systems, there have been some significant advancements in defense technology that could be considered game-changers. One area that comes to mind is the development of advanced materials and composites, such as those used in the US military's Next Generation Combat Vehicle (NGCV) program. These materials are designed to provide improved protection against various types of threats, including ballistic and explosive attacks.\n",
            "\n",
            "Another area of significant advancement is in the field of propulsion systems, particularly in the development of advanced electric propulsion systems for naval vessels. For example, the US Navy is currently testing an advanced electric propulsion system for its Zumwalt-class destroyers, which could potentially provide improved speed, maneuverability, and stealth capabilities.\n",
            "\n",
            "Additionally, there have been significant advancements in the development of advanced munitions, such as the US military's Joint Direct Attack Munition (JDAM) system, which uses GPS and inertial navigation to guide precision-guided bombs to their targets. Another example is the development of advanced rocket propulsion systems, such as the US military's Tactical Boost Glide (TBG) system, which uses a rocket to propel a glide vehicle to its target.\n",
            "\n",
            "I've also noticed significant progress in the development of advanced armor systems, such as the US military's Active Protection System (APS), which\n",
            "Human: That sounds like a significant threat. And what about the other end of the spectrum, smaller, more networked systems?\n",
            "AI: That's a great point, and I'm glad you brought it up. In addition to the larger, more complex systems I mentioned earlier, there have been significant advancements in smaller, more networked systems that could potentially change the nature of modern warfare.\n",
            "\n",
            "One area that comes to mind is the development of small, unmanned ground vehicles (UGVs) that can be used for reconnaissance, surveillance, and even combat. These vehicles are often equipped with advanced sensors, communication systems, and autonomous navigation capabilities, allowing them to operate independently and in coordination with other systems.\n",
            "\n",
            "Another area of significant advancement is in the development of small, networked sensors and communication systems that can be used to create a \"sensor web\" or \"network of sensors\" that can provide real-time information about the battlefield. These systems can include everything from small, handheld sensors to larger, more complex systems that can be used to monitor and track enemy movements.\n",
            "\n",
            "Additionally, there have been significant advancements in the development of small, autonomous systems that can be used for a variety of tasks, such as explosive ordnance disposal (EOD), search and rescue, and even medical evacuation. These systems can be designed to operate in a variety of environments and can be equipped with advanced sensors, communication systems, and autonomous navigation capabilities.\n",
            "\n",
            "\n",
            "Human: So, it's not just about offense, but also defense against these new threats. What about the less visible aspects of warfare, like in the digital realm?\n",
            "AI: The digital realm is a fascinating area of modern warfare, and I'm happy to discuss it with you. In recent years, there has been a significant increase in the use of cyber warfare and information operations to achieve strategic objectives. This includes everything from hacking and cyber espionage to disinformation and propaganda campaigns.\n",
            "\n",
            "One of the most significant advancements in this area is the development of advanced artificial intelligence-powered cyber warfare tools. These tools can be used to launch sophisticated attacks on enemy networks, as well as to defend against such attacks. For example, the US military has been investing in AI-powered cyber defense systems, such as the Advanced Cyber Defense (ACD) system, which uses machine learning algorithms to detect and respond to cyber threats in real-time.\n",
            "\n",
            "Another area of significant advancement is in the field of electronic warfare (EW). EW involves the use of electromagnetic energy to disrupt or destroy enemy communications, radar, and other electronic systems. The US military has been developing advanced EW systems, such as the Next Generation Jammer (NGJ) system, which uses AI-powered algorithms to detect and disrupt enemy communications.\n",
            "\n",
            "In addition to these areas, there has also been significant progress in the development of advanced information operations tools. These tools can be used to spread disinformation, propaganda, and other forms of psychological\n",
            "Human: It sounds like a constant race between developing new offensive technologies and creating defenses against them.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "User: It sounds like a constant race between developing new offensive technologies and creating defenses against them.\n",
            "AI: That's a very astute observation. The development of new technologies in the defense sector is often a cat-and-mouse game, where one side tries to outdo the other in terms of innovation and capabilities. This is particularly true in the area of cyber warfare and electronic warfare, where the lines between offense and defense can become increasingly blurred.\n",
            "\n",
            "In fact, the US military has been investing heavily in the development of \"defensive\" technologies that can counter the effects of cyber attacks and electronic warfare. For example, the US military has been working on the development of advanced cybersecurity systems that can detect and respond to cyber threats in real-time. These systems use machine learning algorithms and other advanced technologies to identify and mitigate the effects of cyber attacks.\n",
            "\n",
            "Similarly, the US military has been investing in the development of advanced electronic warfare systems that can counter the effects of enemy electronic warfare. These systems use AI-powered algorithms to detect and disrupt enemy communications, radar, and other electronic systems.\n",
            "\n",
            "However, it's worth noting that the development of new technologies is not just about offense and defense. It's also about creating new opportunities for cooperation and collaboration between different nations and organizations. For example, the US military has been working with other countries to develop new standards and protocols for cybersecurity and electronic warfare, in order\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n--- Q&A from chat history using a QA Chain ---\\n\")\n",
        "\n",
        "# Prepare chat history as documents for the QA chain\n",
        "history_docs = []\n",
        "for message in memory.buffer_as_messages:\n",
        "    # Convert message to a string and then to a Document\n",
        "    # Ensure the content is always a string, even if the model returns something else for 'content'\n",
        "    content = f\"{message.type.capitalize()}: {str(message.content)}\"\n",
        "    history_docs.append(Document(page_content=content))\n",
        "\n",
        "# Initialize a QA chain using the specified LLM\n",
        "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "def answer_question_from_history(question: str) -> str:\n",
        "    \"\"\"Answers a question by querying the chat history using the QA chain.\"\"\"\n",
        "    result = qa_chain.invoke({\"input_documents\": history_docs, \"question\": question})\n",
        "    return result[\"output_text\"]\n",
        "\n",
        "# Q&A from chat history\n",
        "q1 = \"What is one of the most impactful advancements in defense technology mentioned in our conversation?\"\n",
        "a1 = answer_question_from_history(q1)\n",
        "print(f\"Q: {q1}\\nA: {a1}\\n\")\n",
        "\n",
        "q2 = \"What is the defining characteristic of hypersonic weapons?\"\n",
        "a2 = answer_question_from_history(q2)\n",
        "print(f\"Q: {q2}\\nA: {a2}\\n\")\n",
        "\n",
        "q3 = \"What is a key advantage of drone swarm technology?\"\n",
        "a3 = answer_question_from_history(q3)\n",
        "print(f\"Q: {q3}\\nA: {a3}\\n\")\n",
        "\n",
        "q4 = \"What kind of infrastructure can be targeted in cyber warfare?\"\n",
        "a4 = answer_question_from_history(q4)\n",
        "print(f\"Q: {q4}\\nA: {a4}\\n\")\n",
        "\n",
        "q5 = \"What does the discussion suggest about the overall nature of modern warfare?\"\n",
        "a5 = answer_question_from_history(q5)\n",
        "print(f\"Q: {q5}\\nA: {a5}\\n\")\n",
        "\n",
        "print(\"\\n--- Full Chat History (AI Responses Only) ---\")\n",
        "for i, response_text in enumerate(chat_history_responses):\n",
        "    print(f\"Response {i+1}: {response_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xbbx5Yr784F",
        "outputId": "677afd5a-04c4-4b61-9be1-facaffadb8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Q&A from chat history using a QA Chain ---\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-123d1c1bb0ec>:12: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
            "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
            "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
            "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
            "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
            "\n",
            "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
            "  qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What is one of the most impactful advancements in defense technology mentioned in our conversation?\n",
            "A: One of the most impactful advancements in defense technology mentioned in our conversation is the increasing use of artificial intelligence (AI) and machine learning in defense systems. This includes the development of AI-powered surveillance systems, such as the Advanced Battle Management System (ABMS), which uses machine learning algorithms to analyze vast amounts of data from various sources, including sensors, drones, and satellites.\n",
            "\n",
            "This advancement has the potential to significantly improve the effectiveness of defense systems by enabling them to quickly process and analyze large amounts of data, identify patterns and threats, and make decisions in real-time. This could lead to improved situational awareness, faster response times, and more effective countermeasures against enemy threats.\n",
            "\n",
            "Q: What is the defining characteristic of hypersonic weapons?\n",
            "A: The defining characteristic of hypersonic weapons is their ability to travel at speeds of Mach 5 or higher, which is at least five times the speed of sound (approximately 3,800 mph or 6,116 km/h at sea level). This speed allows hypersonic weapons to evade traditional air defense systems, which are typically designed to intercept slower-moving targets.\n",
            "\n",
            "Hypersonic weapons can maintain their high speed for extended periods of time, often for hundreds of miles, and can make sharp turns and changes in direction, making them difficult to track and intercept. This is due to their ability to operate in the upper atmosphere, where the air is thinner and there is less air resistance, allowing them to maintain their speed and maneuverability.\n",
            "\n",
            "The high speed and maneuverability of hypersonic weapons make them a significant threat to modern air defense systems, which are often designed to intercept slower-moving targets. The development of hypersonic weapons has raised concerns about their potential use in military conflicts and the need for new air defense systems that can counter their capabilities.\n",
            "\n",
            "Q: What is a key advantage of drone swarm technology?\n",
            "A: One of the key advantages of drone swarm technology is its ability to overwhelm and saturate enemy air defenses through sheer numbers. A swarm of drones can be deployed in large quantities, making it difficult for a single air defense system to track and engage each individual drone. This can lead to a significant increase in the chances of successful mission completion, as the enemy's air defenses are overwhelmed by the sheer number of targets.\n",
            "\n",
            "Another advantage of drone swarm technology is its ability to provide a high degree of redundancy and fault tolerance. If one or more drones in the swarm are lost or damaged, the remaining drones can continue to operate and complete the mission. This makes drone swarms more resilient and able to adapt to changing circumstances on the battlefield.\n",
            "\n",
            "Additionally, drone swarms can be used to achieve a variety of mission objectives, including reconnaissance, surveillance, and even combat. They can be equipped with a range of sensors and payloads, including cameras, radar, and missiles, making them a versatile and effective tool for a variety of military operations.\n",
            "\n",
            "Overall, the key advantage of drone swarm technology is its ability to provide a high degree of flexibility, redundancy, and effectiveness in a variety of military operations.\n",
            "\n",
            "Q: What kind of infrastructure can be targeted in cyber warfare?\n",
            "A: In cyber warfare, various types of infrastructure can be targeted to achieve strategic objectives. Some examples include:\n",
            "\n",
            "1. **Critical Infrastructure**: Power grids, water treatment plants, transportation systems, and other essential services that are critical to a nation's or organization's functioning can be targeted to disrupt or destroy them.\n",
            "2. **Communication Networks**: Telecommunication networks, including internet service providers, mobile networks, and satellite communications, can be targeted to disrupt or destroy communication capabilities.\n",
            "3. **Financial Systems**: Banks, stock exchanges, and other financial institutions can be targeted to disrupt or destroy financial transactions and create economic instability.\n",
            "4. **Government Systems**: Government agencies, including those responsible for defense, law enforcement, and public health, can be targeted to disrupt or destroy their operations and create chaos.\n",
            "5. **Industrial Control Systems**: Industrial control systems, including those used in manufacturing, energy, and transportation, can be targeted to disrupt or destroy critical infrastructure and create economic instability.\n",
            "6. **Healthcare Systems**: Healthcare systems, including hospitals and medical research institutions, can be targeted to disrupt or destroy medical services and create public health crises.\n",
            "7. **Supply Chain Systems**: Supply chain systems, including logistics and transportation networks, can be targeted to disrupt or destroy the flow of goods and services.\n",
            "8\n",
            "\n",
            "Q: What does the discussion suggest about the overall nature of modern warfare?\n",
            "A: The discussion suggests that modern warfare is becoming increasingly complex, high-tech, and multifaceted. Here are some key takeaways:\n",
            "\n",
            "1. **Increased reliance on technology**: The discussion highlights the growing importance of technology in modern warfare, including artificial intelligence, machine learning, cyber warfare, and electronic warfare. This suggests that technology is playing a more significant role in shaping the nature of warfare.\n",
            "2. **Asymmetric warfare**: The discussion touches on the idea of asymmetric warfare, where smaller, more agile forces can use advanced technologies to counter larger, more conventional forces. This suggests that modern warfare is becoming more decentralized and unpredictable.\n",
            "3. **Constant innovation and counter-innovation**: The discussion notes that the development of new technologies in the defense sector is often a cat-and-mouse game, where one side tries to outdo the other in terms of innovation and capabilities. This suggests that modern warfare is characterized by a constant cycle of innovation and counter-innovation.\n",
            "4. **Increased emphasis on defense**: The discussion highlights the growing importance of defense in modern warfare, including the development of advanced cybersecurity systems and electronic warfare systems. This suggests that modern warfare is becoming more focused on protecting against threats rather than just launching attacks.\n",
            "5. **Globalization and interconnectivity**: The discussion touches on the\n",
            "\n",
            "\n",
            "--- Full Chat History (AI Responses Only) ---\n",
            "Response 1: Hello there, I'm delighted to make your acquaintance. I'm an artificial intelligence model known as Lumin, and I'm a large language model specifically designed to assist and converse with humans in a friendly and informative manner. I was created by a team of researchers at Meta AI, and I'm based on a transformer architecture that allows me to process and understand human language in a highly efficient and accurate way.\n",
            "\n",
            "I have been trained on a massive corpus of text data that includes a wide range of topics, from science and history to entertainment and culture. This training data includes over 1.5 trillion parameters, which allows me to generate responses that are not only accurate but also engaging and informative.\n",
            "\n",
            "I'm a bit like a digital librarian, but instead of just providing book recommendations, I can answer questions, provide explanations, and even engage in conversations on a wide range of topics. So, feel free to ask me anything, and I'll do my best to help!\n",
            "Response 2: I'd be happy to help you with the weather. However, I don't have real-time access to current weather conditions. I can suggest some ways for you to find out the current weather, though. You can check online weather websites such as AccuWeather or the National Weather Service, or you can use a mobile app like Dark Sky or Weather Underground. These services provide up-to-date weather forecasts and conditions for locations all around the world.\n",
            "\n",
            "That being said, I can tell you about the general weather patterns for different regions and seasons. If you'd like to know about the typical weather conditions for a specific location or time of year, I'd be happy to help. Just let me know where you're interested in learning about!\n",
            "Response 3: Defense technology is a fascinating field, and I've been trained on a vast amount of information about the latest developments in this area. One of the most significant advancements I've observed is the increasing use of artificial intelligence and machine learning in defense systems. For example, the US military has been investing heavily in AI-powered surveillance systems, such as the Advanced Battle Management System (ABMS), which uses machine learning algorithms to analyze vast amounts of data from various sources, including sensors, drones, and satellites.\n",
            "\n",
            "Another significant advancement is the development of hypersonic missiles, which can travel at speeds of over Mach 5 (five times the speed of sound). Countries like the US, China, and Russia are actively working on hypersonic missile systems, which could potentially revolutionize the way we think about air defense.\n",
            "\n",
            "I've also noticed significant progress in the field of unmanned aerial vehicles (UAVs), also known as drones. The US military has been using drones extensively in combat zones, and they've also been exploring the use of swarms of drones to overwhelm enemy air defenses. Additionally, there's been a growing interest in the development of autonomous underwater vehicles (AUVs) for marine surveillance and reconnaissance.\n",
            "\n",
            "Another area of significant advancement is in the field of directed energy systems, such as high\n",
            "Response 4: In terms of physical systems, there have been some significant advancements in defense technology that could be considered game-changers. One area that comes to mind is the development of advanced materials and composites, such as those used in the US military's Next Generation Combat Vehicle (NGCV) program. These materials are designed to provide improved protection against various types of threats, including ballistic and explosive attacks.\n",
            "\n",
            "Another area of significant advancement is in the field of propulsion systems, particularly in the development of advanced electric propulsion systems for naval vessels. For example, the US Navy is currently testing an advanced electric propulsion system for its Zumwalt-class destroyers, which could potentially provide improved speed, maneuverability, and stealth capabilities.\n",
            "\n",
            "Additionally, there have been significant advancements in the development of advanced munitions, such as the US military's Joint Direct Attack Munition (JDAM) system, which uses GPS and inertial navigation to guide precision-guided bombs to their targets. Another example is the development of advanced rocket propulsion systems, such as the US military's Tactical Boost Glide (TBG) system, which uses a rocket to propel a glide vehicle to its target.\n",
            "\n",
            "I've also noticed significant progress in the development of advanced armor systems, such as the US military's Active Protection System (APS), which\n",
            "Response 5: That's a great point, and I'm glad you brought it up. In addition to the larger, more complex systems I mentioned earlier, there have been significant advancements in smaller, more networked systems that could potentially change the nature of modern warfare.\n",
            "\n",
            "One area that comes to mind is the development of small, unmanned ground vehicles (UGVs) that can be used for reconnaissance, surveillance, and even combat. These vehicles are often equipped with advanced sensors, communication systems, and autonomous navigation capabilities, allowing them to operate independently and in coordination with other systems.\n",
            "\n",
            "Another area of significant advancement is in the development of small, networked sensors and communication systems that can be used to create a \"sensor web\" or \"network of sensors\" that can provide real-time information about the battlefield. These systems can include everything from small, handheld sensors to larger, more complex systems that can be used to monitor and track enemy movements.\n",
            "\n",
            "Additionally, there have been significant advancements in the development of small, autonomous systems that can be used for a variety of tasks, such as explosive ordnance disposal (EOD), search and rescue, and even medical evacuation. These systems can be designed to operate in a variety of environments and can be equipped with advanced sensors, communication systems, and autonomous navigation capabilities.\n",
            "\n",
            "\n",
            "Response 6: The digital realm is a fascinating area of modern warfare, and I'm happy to discuss it with you. In recent years, there has been a significant increase in the use of cyber warfare and information operations to achieve strategic objectives. This includes everything from hacking and cyber espionage to disinformation and propaganda campaigns.\n",
            "\n",
            "One of the most significant advancements in this area is the development of advanced artificial intelligence-powered cyber warfare tools. These tools can be used to launch sophisticated attacks on enemy networks, as well as to defend against such attacks. For example, the US military has been investing in AI-powered cyber defense systems, such as the Advanced Cyber Defense (ACD) system, which uses machine learning algorithms to detect and respond to cyber threats in real-time.\n",
            "\n",
            "Another area of significant advancement is in the field of electronic warfare (EW). EW involves the use of electromagnetic energy to disrupt or destroy enemy communications, radar, and other electronic systems. The US military has been developing advanced EW systems, such as the Next Generation Jammer (NGJ) system, which uses AI-powered algorithms to detect and disrupt enemy communications.\n",
            "\n",
            "In addition to these areas, there has also been significant progress in the development of advanced information operations tools. These tools can be used to spread disinformation, propaganda, and other forms of psychological\n",
            "Response 7: That's a very astute observation. The development of new technologies in the defense sector is often a cat-and-mouse game, where one side tries to outdo the other in terms of innovation and capabilities. This is particularly true in the area of cyber warfare and electronic warfare, where the lines between offense and defense can become increasingly blurred.\n",
            "\n",
            "In fact, the US military has been investing heavily in the development of \"defensive\" technologies that can counter the effects of cyber attacks and electronic warfare. For example, the US military has been working on the development of advanced cybersecurity systems that can detect and respond to cyber threats in real-time. These systems use machine learning algorithms and other advanced technologies to identify and mitigate the effects of cyber attacks.\n",
            "\n",
            "Similarly, the US military has been investing in the development of advanced electronic warfare systems that can counter the effects of enemy electronic warfare. These systems use AI-powered algorithms to detect and disrupt enemy communications, radar, and other electronic systems.\n",
            "\n",
            "However, it's worth noting that the development of new technologies is not just about offense and defense. It's also about creating new opportunities for cooperation and collaboration between different nations and organizations. For example, the US military has been working with other countries to develop new standards and protocols for cybersecurity and electronic warfare, in order\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 12. **LLMCheckerChain** – Verification & correction loop\n",
        "\n",
        "> Use an LLM to **check another LLM’s output**, and refine if needed.\n",
        "\n",
        "✅ Best for: Safety checks or multi-step validation using LLMs.\n"
      ],
      "metadata": {
        "id": "ICPkOUtZ9s3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import LLMCheckerChain\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "\n",
        "# Initialize LLM for some chains\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.5,\n",
        "    max_tokens=1024,\n",
        "    timeout=5,\n",
        "    max_retries=2\n",
        ")\n",
        "\n",
        "# Define the initial translation chain using LCEL\n",
        "translate_prompt = PromptTemplate.from_template(\"Translate '{sentence}' to Bengali\")\n",
        "translate_chain = translate_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Define a checking prompt\n",
        "check_prompt = PromptTemplate.from_template(\"\"\"\n",
        "You are a language checker. Given an original English sentence and a proposed Bengali translation,\n",
        "evaluate if the translation is accurate and grammatically correct.\n",
        "If it is accurate, just output \"ACCURATE\".\n",
        "If it is not accurate or incorrect, explain why and provide a corrected translation in Bengali.\n",
        "\n",
        "Original English Sentence: {original_sentence}\n",
        "Proposed Bengali Translation: {translated_sentence}\n",
        "\n",
        "Evaluation:\n",
        "\"\"\")\n",
        "\n",
        "# Define the checking chain\n",
        "check_chain = check_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Combine the translation and checking chains using LCEL\n",
        "# This runnable first translates the sentence and then uses the output\n",
        "# along with the original sentence for the checking chain.\n",
        "full_checking_process = RunnableParallel(\n",
        "    original_sentence=RunnablePassthrough(), # Pass the input sentence as original_sentence\n",
        "    translated_sentence=translate_chain # Run the translation chain\n",
        ") | check_chain # Pipe the output of the parallel block into the check chain\n",
        "\n",
        "print(\"--- Testing Translation and Checking Chain ---\")\n",
        "\n",
        "# Invoke the combined process\n",
        "sentence_to_check = \"A drone swarm technology has the ability to overwhelm and saturate enemy air defenses through sheer numbers\"\n",
        "result = full_checking_process.invoke(sentence_to_check)\n",
        "\n",
        "print(f\"Original Sentence: {sentence_to_check}\")\n",
        "print(f\"Checking Result:\\n{result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzixYPE-9lsx",
        "outputId": "1392132e-3570-4faf-a10e-d09485a93d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Translation and Checking Chain ---\n",
            "Original Sentence: A drone swarm technology has the ability to overwhelm and saturate enemy air defenses through sheer numbers\n",
            "Checking Result:\n",
            "The proposed Bengali translation is not entirely accurate. \n",
            "\n",
            "The original English sentence uses the phrase \"overwhelm and saturate\" which implies a continuous and intense attack. However, the proposed translation uses the phrase \"সম্পূর্ণরূপে নষ্ট করে দেওয়ার\" which means \"completely destroy\" which is more like a one-time action.\n",
            "\n",
            "A more accurate translation would be: ড্রোন সুইম প্রযুক্তির ক্ষমতা আছে বিপজ্জনক শত্রু বিমান ব্যবস্থাপনা সুরক্ষা ভেঙে দেওয়ার এবং সংখ্যার মাধ্যমে তা সমৃদ্ধ করে দেওয়ার।\n",
            "\n",
            "However, a more idiomatic translation would be: ড্রোন সুইম প্রযুক্তির ক্ষমতা আছে বিপজ্জনক শত্রু বিমান ব্যবস্থাপনা সুরক্ষাকে ভেঙে দিতে এবং সংখ্যার মাধ্যমে তাদের সুরক্ষাকে অতিমাত্রায় সমৃদ্ধ করে দিতে।\n",
            "\n",
            "Note: অতিমাত্রায় সমৃদ্ধ করে দিতে is a more idiomatic translation of \"saturate\" in this context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 13. **Self-AskWithSearchChain** – Ask → Plan → Search → Answer\n",
        "\n"
      ],
      "metadata": {
        "id": "rX743iUl9jBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain-tavily"
      ],
      "metadata": {
        "id": "RKYkk6xSpEOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "\n",
        "# Initialize LLM for some chains\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=256,\n",
        "    timeout=2,\n",
        "    max_retries=3\n",
        ")\n",
        "\n",
        "# Use Tavily Search Results tool instead of Google Search\n",
        "search = TavilySearchResults()\n",
        "tools = [search]\n",
        "\n",
        "# Create the prompt for the agent\n",
        "# This prompt guides the LLM to decide when and how to use the search tool\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful AI assistant. You have access to a search tool to find information.\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "\n",
        "# Create the agent\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "\n",
        "# Create the agent executor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "print(\"=== SEARCH-AUGMENTED AGENT TEST ===\")\n",
        "\n",
        "# Invoke the agent with the question\n",
        "# Note: The input variable is typically 'input' for agents\n",
        "result = agent_executor.invoke({\"input\": \"Give the % change of all sectorial index performace in Indian stock market on today?\"})\n",
        "\n",
        "print(\"\\n============Result==========================\\n\")\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRHD63LN-0oQ",
        "outputId": "b071ca60-ec35-4480-ce35-ce9cefa00d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SEARCH-AUGMENTED AGENT TEST ===\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `tavily_search_results_json` with `{'query': 'Indian stock market sectorial index performance today % change'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'All NSE Sectoral Indices in India', 'url': 'https://www.etmoney.com/stocks/market-data/sectoral-indices/32', 'content': 'Indices | Price | 1D Change % | 1W Change % | 1Y Change % | 3Y Change %\\nNifty Auto | 23,763.15 | +1.05 | -1.20 | -0.54 | +114.14\\nNifty Bank | 55,572.00 | +0.31 | +0.27 | +13.48 | +58.35\\nNifty Commodities | 8,764.85 | +0.46 | -0.23 | -4.12 | +62.16\\nNifty CPSE | 6,537.70 | +0.11 | +0.31 | -3.49 | +156.27\\nNifty Energy | 35,882.60 | +0.69 | +0.54 | -13.82 | +39.29\\nNifty FMCG | 57,049.70 | +0.97 | +0.17 | +2.89 | +50.73\\nNifty IT | 37,785.90 | +1.02 | +0.82 | +11.71 | +35.28 [...] Nifty Media | 1,691.50 | +0.50 | +1.19 | -10.83 | -11.49\\nNifty Metal | 9,336.45 | +0.94 | +1.36 | -5.96 | +79.04\\nNifty MNC | 28,187.15 | +0.44 | -0.20 | -3.33 | +58.47\\nNifty Pharma | 21,501.80 | +0.32 | -1.10 | +12.46 | +71.23\\nNifty PSE | 10,011.00 | +0.65 | +0.46 | -7.53 | +149.72\\nNifty PSU Bank | 6,714.30 | +0.17 | -0.16 | -8.76 | +168.37\\nNifty Realty | 944.00 | +0.76 | +1.16 | -7.78 | +144.56\\nTop Gainers: [...] BEML Ltd.\\n\\nGE Vernova T&D India Ltd.\\n\\nEmcure Pharmaceuticals Ltd.\\n\\nGillette India Ltd.\\n\\nLinde India Ltd.\\n\\nTop Losers:\\n\\nBalkrishna Industries Ltd.\\n\\nSarda Energy & Minerals Ltd.\\n\\nHitachi Energy India Ltd.\\n\\nEternal Ltd.\\n\\nHonasa Consumer Ltd.\\n\\nLarge Cap Stocks:\\n\\nReliance Industries Ltd.\\n\\nTata Consultancy Services Ltd.\\n\\nHDFC Bank Ltd.\\n\\nBharti Airtel Ltd.\\n\\nICICI Bank Ltd.\\n\\nMid Cap Stocks:\\n\\nSwiggy Ltd.\\n\\nJindal Steel & Power Ltd.\\n\\nUnion Bank of India\\n\\nPolycab India Ltd.', 'score': 0.7944651}, {'title': 'BSE SENSEX Stock Market Index - Quote - Chart', 'url': 'https://tradingeconomics.com/india/stock-market', 'content': \"The main stock market index in India (SENSEX) increased 4037 points or 5.17% since the beginning of 2025, according to trading on a contract for difference (CFD) that tracks this benchmark index from India.  Historically, the BSE SENSEX Stock Market Index reached an all time high of 85978.25 in September of 2024. BSE SENSEX Stock Market Index - data, forecasts, historical chart - was last updated on  May 26 of 2025. [...] India's BSE Sensex closed about 0.6% up at 82,176.5 on Monday, its highest since mid-May and extending gains from the previous session. Buying was widespread across sectors, led by autos, banks, metals and IT. The rally reflected renewed optimism in domestic and global markets following a market-calming announcement by US President Donald Trump, who extended the deadline for trade negotiations with the European Union until July 9. At the same time, domestic fundamentals remain supportive, [...] The main stock market index in India (SENSEX) increased 4037 points or 5.17% since the beginning of 2025, according to trading on a contract for difference (CFD) that tracks this benchmark index from India. The BSE SENSEX Stock Market Index is expected to trade at 80854.83 points by the end of this quarter, according to Trading Economics global macro models and analysts expectations. Looking forward, we estimate it to trade at 78313.31 in 12 months time.\", 'score': 0.694241}, {'title': 'Performance of Indices -BSE & NSE ...', 'url': 'https://www.moneycontrol.com/stocks/marketstats/ind_performance/index.php', 'content': 'Indices Graph. Sensex; Nifty. Indian Indices. Index, Current Value, Change % Chg. S&P BSE Sensex, 82176.45, 455.37 0.55. NIFTY 50, 25001.15, 148.00 0.59. S&P', 'score': 0.67911536}, {'title': 'Stock Market Sector Analysis and Performance', 'url': 'https://www.moneycontrol.com/markets/sector-analysis/', 'content': 'Smallcap, midcap stocks rise up to 15%, broader market indices extend gains for second day; check top gainers. May 26, 2025 3:54 AM IST. Generics drugs are a', 'score': 0.51735204}, {'title': 'India Stock Indices', 'url': 'https://www.investing.com/indices/india-indices', 'content': 'India - Indices ; BSE Sensex. 26/05 |BSESN. 82,176.45. +455.37+0.56 ; Nifty Midcap 150. 26/05 |NIMI150. 20,991.00. +116.60+0.56 ; Nifty 50. 26/05 |NSEI. 25,001.15.', 'score': 0.4237686}]\u001b[0m\u001b[32;1m\u001b[1;3mThe performance of sectorial indices in the Indian stock market on today is as follows:\n",
            "\n",
            "- Nifty Auto: +1.05% \n",
            "- Nifty Bank: +0.31% \n",
            "- Nifty Commodities: +0.46% \n",
            "- Nifty CPSE: +0.11% \n",
            "- Nifty Energy: +0.69% \n",
            "- Nifty FMCG: +0.97% \n",
            "- Nifty IT: +1.02% \n",
            "- Nifty Media: +0.50% \n",
            "- Nifty Metal: +0.94% \n",
            "- Nifty MNC: +0.44% \n",
            "- Nifty Pharma: +0.32% \n",
            "- Nifty PSE: +0.65% \n",
            "- Nifty PSU Bank: +0.17% \n",
            "- Nifty Realty: +0.76%\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "============Result==========================\n",
            "\n",
            "The performance of sectorial indices in the Indian stock market on today is as follows:\n",
            "\n",
            "- Nifty Auto: +1.05% \n",
            "- Nifty Bank: +0.31% \n",
            "- Nifty Commodities: +0.46% \n",
            "- Nifty CPSE: +0.11% \n",
            "- Nifty Energy: +0.69% \n",
            "- Nifty FMCG: +0.97% \n",
            "- Nifty IT: +1.02% \n",
            "- Nifty Media: +0.50% \n",
            "- Nifty Metal: +0.94% \n",
            "- Nifty MNC: +0.44% \n",
            "- Nifty Pharma: +0.32% \n",
            "- Nifty PSE: +0.65% \n",
            "- Nifty PSU Bank: +0.17% \n",
            "- Nifty Realty: +0.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 14. **LCEL (LangChain Expression Language)** – Declarative Chain Composition\n",
        "\n",
        "> **NEW, recommended** for composability, clarity, and tight control.\n",
        "\n",
        "\n",
        "\n",
        "✅ Best for: Clean, Pythonic pipelines with intermediate state access."
      ],
      "metadata": {
        "id": "tfCGWxZNABdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_together import Together\n",
        "\n",
        "llm = Together(\n",
        "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
        "    temperature=0.2,\n",
        "    max_tokens=512,\n",
        "    # timeout=2,\n",
        "    # max_retries=1,\n",
        ")\n",
        "\n",
        "# # Initialize LLM for some chains\n",
        "# llm = ChatGroq(\n",
        "#     model=\"llama-3.1-8b-instant\",\n",
        "#     temperature=0.7,\n",
        "#     max_tokens=1024,\n",
        "#     timeout=6,\n",
        "#     max_retries=3\n",
        "# )\n",
        "\n",
        "\n",
        "chain = (\n",
        "    {\"topic\": RunnablePassthrough()}\n",
        "    | PromptTemplate.from_template(\"Write a sanskrit shloka about {topic} from Mahabharat time period\")\n",
        "    | llm\n",
        ")\n",
        "\n",
        "result = chain.invoke(\"time travel\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "l1miVgBj9ftn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dbc845d-8e27-4b15-c494-7e03a0d559cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Here's a Sanskrit shloka that might fit the bill:\n",
            "\n",
            "\"कालचक्रे परिभ्रमन्, युगानां परिवर्तनम् |\n",
            "दृश्यन्ते भूतपूर्वाणि, भविष्याणि च पश्यन् ||\"\n",
            "\n",
            "Transliteration: \"Kālacakra paribhraman, yugānāṁ parivartanam |\n",
            "Dṛśyante bhūtapūrvāṇi, bhaviṣyāṇi ca paśyan ||\"\n",
            "\n",
            "Translation: \"As one travels through the cycle of time, witnessing the transformation of ages |\n",
            "One sees the past and the future, and beholds the events that have been and those that will be ||\"\n",
            "\n",
            "This shloka is inspired by the style of the Mahabharata, but please note that it is not an actual quote from the epic. The language and meter are intended to evoke the spirit of ancient Sanskrit poetry.\n",
            "\n",
            "In this shloka, the phrase \"कालचक्रे परिभ्रमन्\" (Kālacakra paribhraman) suggests the idea of traveling through the cycle of time, while \"युगानां परिवर्तनम्\" (yugānāṁ parivartanam) refers to the transformation of ages or epochs. The second line, \"दृश्यन्ते भूतपूर्वाणि, भविष्याणि च पश्यन्\" (Dṛśyante bhūtapūrvāṇi, bhaviṣyāṇi ca paśyan), implies that the time traveler is able to see both the past and the future, and behold the events that have occurred and those that will occur.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## 🔹 15. **SQLDatabaseChain** – Query SQL DB using natural language\n",
        "\n",
        "✅ Best for: Natural language to SQL querying with LLM.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gnax9wGlWxhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U  sqlalchemy ipython-sql langchain_experimental"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAORuvarCRRi",
        "outputId": "1a294f8c-917f-4160-a08e-5590fd85c273"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import os\n",
        "\n",
        "db_file = \"mydb.db\"\n",
        "\n",
        "# Remove existing DB to start fresh\n",
        "if os.path.exists(db_file):\n",
        "    os.remove(db_file)\n",
        "\n",
        "# Create and populate the database\n",
        "conn = sqlite3.connect(db_file)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create a 'users' table\n",
        "cursor.execute('''\n",
        "CREATE TABLE users (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    username TEXT NOT NULL,\n",
        "    signup_date DATE NOT NULL\n",
        ");\n",
        "''')\n",
        "\n",
        "# Insert dummy data\n",
        "cursor.execute(\"INSERT INTO users (username, signup_date) VALUES ('Alice', '2025-05-20')\")\n",
        "cursor.execute(\"INSERT INTO users (username, signup_date) VALUES ('Bob', '2025-05-21')\")\n",
        "cursor.execute(\"INSERT INTO users (username, signup_date) VALUES ('Charlie', '2025-05-22')\")\n",
        "cursor.execute(\"INSERT INTO users (username, signup_date) VALUES ('David', '2025-05-23')\")\n",
        "cursor.execute(\"INSERT INTO users (username, signup_date) VALUES ('Eve', '2025-05-10')\")  # Old user\n",
        "cursor.execute(\"INSERT INTO users (username, signup_date) VALUES ('Frank', '2025-05-24')\")\n",
        "cursor.execute(\"INSERT INTO users (username, signup_date) VALUES ('Grace', '2025-05-25')\")\n",
        "\n",
        "conn.commit()\n",
        "conn.close()\n",
        "print(f\"Database '{db_file}' created and populated successfully.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WTvJfhWCnE_",
        "outputId": "8cda6ae4-e27b-49a7-924d-7810dee02f32"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database 'mydb.db' created and populated successfully.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # To inspect the tables (optional, using ipython-sql for convenience)\n",
        "# %load_ext sql\n",
        "# %sql sqlite:///mydb.db\n",
        "\n",
        "# %config SqlMagic.style='DEFAULT' # Use a supported style instead\n",
        "\n",
        "\n",
        "# %sql SELECT * FROM users;"
      ],
      "metadata": {
        "id": "zZmR9H7hC0XW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.sql_database import SQLDatabase\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain_together import Together\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.2,\n",
        "    max_tokens=256,\n",
        "    timeout=2,\n",
        "    max_retries=2\n",
        ")\n",
        "\n",
        "# llm = Together(\n",
        "#     model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
        "#     temperature=0.2,\n",
        "#     max_tokens=1024,\n",
        "#     # timeout=2,\n",
        "#     # max_retries=1,\n",
        "# )\n",
        "\n",
        "\n",
        "# Load the database using SQLAlchemy-style URI\n",
        "db = SQLDatabase.from_uri(f\"sqlite:///{db_file}\")\n",
        "\n",
        "# Improved custom prompt to handle fixed date correctly\n",
        "custom_prompt = PromptTemplate.from_template(\"\"\"\n",
        "You are a SQLite expert. Given a question, write a syntactically correct SQL query for SQLite.\n",
        "\n",
        "- Do not include any Markdown formatting like triple backticks (```).\n",
        "- Just return the raw SQL query — nothing else.\n",
        "- Assume today's date is '2025-05-27'.\n",
        "\n",
        "{table_info}\n",
        "\n",
        "Question: {input}\n",
        "SQLQuery:\n",
        "\"\"\")\n",
        "\n",
        "# Initialize the SQLDatabaseChain\n",
        "sql_chain = SQLDatabaseChain.from_llm(\n",
        "    llm=llm,\n",
        "    db=db,\n",
        "    prompt=custom_prompt,\n",
        "    verbose=True,\n",
        "    return_intermediate_steps=True,\n",
        "    use_query_checker=False  # Disable to avoid rewriting correct date logic\n",
        ")\n",
        "\n",
        "\n",
        "# 1. Count users signed up last week\n",
        "print(\"Query 1: Users signed up last week (based on 2025-05-27):\")\n",
        "result1 = sql_chain.invoke({\"query\": \"How many users signed up last week? (Assume today is 2025-05-27)\"})\n",
        "print(f\"Generated SQL: {result1['intermediate_steps']}\")\n",
        "print(f\"Answer: {result1['result']}\")\n",
        "\n",
        "# 2. List users who signed up today\n",
        "print(\"\\nQuery 2: Users who signed up today (2025-05-27):\")\n",
        "result2 = sql_chain.invoke({\"query\": \"List all users who signed up today. (Assume today is 2025-05-27)\"})\n",
        "print(f\"Generated SQL: {result2['intermediate_steps']}\")\n",
        "print(f\"Answer: {result2['result']}\")\n",
        "\n",
        "# 3. Signups per day for the past 7 days\n",
        "print(\"\\nQuery 3: Daily signups for the past 7 days:\")\n",
        "result3 = sql_chain.invoke({\"query\": \"How many users signed up on each day in the last 7 days? (Assume today is 2025-05-27)\"})\n",
        "print(f\"Generated SQL: {result3['intermediate_steps']}\")\n",
        "print(f\"Answer: {result3['result']}\")"
      ],
      "metadata": {
        "id": "pT_9Mn_99c7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa35e4ea-aba5-4174-f491-fefde9fb9964"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query 1: Users signed up last week (based on 2025-05-27):\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "How many users signed up last week? (Assume today is 2025-05-27)\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT COUNT(*) \n",
            "FROM users \n",
            "WHERE signup_date >= DATE('2025-05-20') AND signup_date <= DATE('2025-05-27')\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[(6,)]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3mSELECT COUNT(*) \n",
            "FROM users \n",
            "WHERE signup_date >= DATE('2025-05-20') AND signup_date <= DATE('2025-05-27')\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Generated SQL: [{'input': 'How many users signed up last week? (Assume today is 2025-05-27)\\nSQLQuery:', 'top_k': '5', 'dialect': 'sqlite', 'table_info': '\\nCREATE TABLE users (\\n\\tid INTEGER, \\n\\tusername TEXT NOT NULL, \\n\\tsignup_date DATE NOT NULL, \\n\\tPRIMARY KEY (id)\\n)\\n\\n/*\\n3 rows from users table:\\nid\\tusername\\tsignup_date\\n1\\tAlice\\t2025-05-20\\n2\\tBob\\t2025-05-21\\n3\\tCharlie\\t2025-05-22\\n*/', 'stop': ['\\nSQLResult:']}, \"SELECT COUNT(*) \\nFROM users \\nWHERE signup_date >= DATE('2025-05-20') AND signup_date <= DATE('2025-05-27')\", {'sql_cmd': \"SELECT COUNT(*) \\nFROM users \\nWHERE signup_date >= DATE('2025-05-20') AND signup_date <= DATE('2025-05-27')\"}, '[(6,)]', {'input': \"How many users signed up last week? (Assume today is 2025-05-27)\\nSQLQuery:SELECT COUNT(*) \\nFROM users \\nWHERE signup_date >= DATE('2025-05-20') AND signup_date <= DATE('2025-05-27')\\nSQLResult: [(6,)]\\nAnswer:\", 'top_k': '5', 'dialect': 'sqlite', 'table_info': '\\nCREATE TABLE users (\\n\\tid INTEGER, \\n\\tusername TEXT NOT NULL, \\n\\tsignup_date DATE NOT NULL, \\n\\tPRIMARY KEY (id)\\n)\\n\\n/*\\n3 rows from users table:\\nid\\tusername\\tsignup_date\\n1\\tAlice\\t2025-05-20\\n2\\tBob\\t2025-05-21\\n3\\tCharlie\\t2025-05-22\\n*/', 'stop': ['\\nSQLResult:']}, \"SELECT COUNT(*) \\nFROM users \\nWHERE signup_date >= DATE('2025-05-20') AND signup_date <= DATE('2025-05-27')\"]\n",
            "Answer: SELECT COUNT(*) \n",
            "FROM users \n",
            "WHERE signup_date >= DATE('2025-05-20') AND signup_date <= DATE('2025-05-27')\n",
            "\n",
            "Query 2: Users who signed up today (2025-05-27):\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "List all users who signed up today. (Assume today is 2025-05-27)\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT * FROM users WHERE signup_date = '2025-05-27'\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3mSELECT * FROM users WHERE signup_date = '2025-05-27'\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Generated SQL: [{'input': 'List all users who signed up today. (Assume today is 2025-05-27)\\nSQLQuery:', 'top_k': '5', 'dialect': 'sqlite', 'table_info': '\\nCREATE TABLE users (\\n\\tid INTEGER, \\n\\tusername TEXT NOT NULL, \\n\\tsignup_date DATE NOT NULL, \\n\\tPRIMARY KEY (id)\\n)\\n\\n/*\\n3 rows from users table:\\nid\\tusername\\tsignup_date\\n1\\tAlice\\t2025-05-20\\n2\\tBob\\t2025-05-21\\n3\\tCharlie\\t2025-05-22\\n*/', 'stop': ['\\nSQLResult:']}, \"SELECT * FROM users WHERE signup_date = '2025-05-27'\", {'sql_cmd': \"SELECT * FROM users WHERE signup_date = '2025-05-27'\"}, '', {'input': \"List all users who signed up today. (Assume today is 2025-05-27)\\nSQLQuery:SELECT * FROM users WHERE signup_date = '2025-05-27'\\nSQLResult: \\nAnswer:\", 'top_k': '5', 'dialect': 'sqlite', 'table_info': '\\nCREATE TABLE users (\\n\\tid INTEGER, \\n\\tusername TEXT NOT NULL, \\n\\tsignup_date DATE NOT NULL, \\n\\tPRIMARY KEY (id)\\n)\\n\\n/*\\n3 rows from users table:\\nid\\tusername\\tsignup_date\\n1\\tAlice\\t2025-05-20\\n2\\tBob\\t2025-05-21\\n3\\tCharlie\\t2025-05-22\\n*/', 'stop': ['\\nSQLResult:']}, \"SELECT * FROM users WHERE signup_date = '2025-05-27'\"]\n",
            "Answer: SELECT * FROM users WHERE signup_date = '2025-05-27'\n",
            "\n",
            "Query 3: Daily signups for the past 7 days:\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "How many users signed up on each day in the last 7 days? (Assume today is 2025-05-27)\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT signup_date, COUNT(*) \n",
            "FROM users \n",
            "WHERE signup_date BETWEEN '2025-05-20' AND '2025-05-27' \n",
            "GROUP BY signup_date\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[('2025-05-20', 1), ('2025-05-21', 1), ('2025-05-22', 1), ('2025-05-23', 1), ('2025-05-24', 1), ('2025-05-25', 1)]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3mSELECT signup_date, COUNT(*) \n",
            "FROM users \n",
            "WHERE signup_date BETWEEN '2025-05-20' AND '2025-05-27' \n",
            "GROUP BY signup_date\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Generated SQL: [{'input': 'How many users signed up on each day in the last 7 days? (Assume today is 2025-05-27)\\nSQLQuery:', 'top_k': '5', 'dialect': 'sqlite', 'table_info': '\\nCREATE TABLE users (\\n\\tid INTEGER, \\n\\tusername TEXT NOT NULL, \\n\\tsignup_date DATE NOT NULL, \\n\\tPRIMARY KEY (id)\\n)\\n\\n/*\\n3 rows from users table:\\nid\\tusername\\tsignup_date\\n1\\tAlice\\t2025-05-20\\n2\\tBob\\t2025-05-21\\n3\\tCharlie\\t2025-05-22\\n*/', 'stop': ['\\nSQLResult:']}, \"SELECT signup_date, COUNT(*) \\nFROM users \\nWHERE signup_date BETWEEN '2025-05-20' AND '2025-05-27' \\nGROUP BY signup_date\", {'sql_cmd': \"SELECT signup_date, COUNT(*) \\nFROM users \\nWHERE signup_date BETWEEN '2025-05-20' AND '2025-05-27' \\nGROUP BY signup_date\"}, \"[('2025-05-20', 1), ('2025-05-21', 1), ('2025-05-22', 1), ('2025-05-23', 1), ('2025-05-24', 1), ('2025-05-25', 1)]\", {'input': \"How many users signed up on each day in the last 7 days? (Assume today is 2025-05-27)\\nSQLQuery:SELECT signup_date, COUNT(*) \\nFROM users \\nWHERE signup_date BETWEEN '2025-05-20' AND '2025-05-27' \\nGROUP BY signup_date\\nSQLResult: [('2025-05-20', 1), ('2025-05-21', 1), ('2025-05-22', 1), ('2025-05-23', 1), ('2025-05-24', 1), ('2025-05-25', 1)]\\nAnswer:\", 'top_k': '5', 'dialect': 'sqlite', 'table_info': '\\nCREATE TABLE users (\\n\\tid INTEGER, \\n\\tusername TEXT NOT NULL, \\n\\tsignup_date DATE NOT NULL, \\n\\tPRIMARY KEY (id)\\n)\\n\\n/*\\n3 rows from users table:\\nid\\tusername\\tsignup_date\\n1\\tAlice\\t2025-05-20\\n2\\tBob\\t2025-05-21\\n3\\tCharlie\\t2025-05-22\\n*/', 'stop': ['\\nSQLResult:']}, \"SELECT signup_date, COUNT(*) \\nFROM users \\nWHERE signup_date BETWEEN '2025-05-20' AND '2025-05-27' \\nGROUP BY signup_date\"]\n",
            "Answer: SELECT signup_date, COUNT(*) \n",
            "FROM users \n",
            "WHERE signup_date BETWEEN '2025-05-20' AND '2025-05-27' \n",
            "GROUP BY signup_date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fEQzF5HyCBSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 🧠 Pro Tips\n",
        "\n",
        "* Use **LangChain Expression Language (LCEL)** for composable chains in a more readable format.\n",
        "* You can add **callbacks/logging** with `verbose=True` or via `LangchainTracer`.\n",
        "* All chains return a dictionary by default. Use `.run()` for string output (when supported).\n",
        "* For **streaming responses**, pass `streaming=True` to the LLM and set a callback handler.\n",
        "\n"
      ],
      "metadata": {
        "id": "uFFzqkYi8a8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ✅ **LangChain Chains Comparison Table**\n",
        "\n",
        "| Chain Name                         | Use Case                         | Level of Control | Memory Efficient? | Best When...                                        |\n",
        "| ---------------------------------- | -------------------------------- | ---------------- | ----------------- | --------------------------------------------------- |\n",
        "| `LLMChain`                         | Basic prompt → response          | 🔹 High          | ✅ Yes             | You want simple LLM prompt/response interaction     |\n",
        "| `SequentialChain`                  | Multi-step deterministic process | 🔹🔹 Very High   | ✅ Yes             | Steps have fixed order and dependent outputs        |\n",
        "| `RouterChain` / `MultiPromptChain` | Route to specialized chains      | 🔹🔹 Very High   | ✅ Yes             | Inputs need dynamic routing based on topic/intent   |\n",
        "| `StuffDocumentsChain`              | All docs → one input             | 🔸 Low           | ❌ No              | All text fits in one prompt                         |\n",
        "| `MapReduceDocumentsChain`          | Large docs → partial + merge     | 🔹 Medium        | ✅ Yes             | Text is large or needs chunked summarization        |\n",
        "| `RefineDocumentsChain`             | Iterative improvement            | 🔹 Medium        | ✅ Yes             | Each new doc should modify prior output             |\n",
        "| `ConversationalChain`              | Stateful LLM convo               | 🔹 Medium        | ✅ Yes             | Chat history must persist                           |\n",
        "| `TransformChain`                   | Preprocessing / postprocessing   | 🔹🔹 Very High   | ✅ Yes             | You need full control over I/O shaping              |\n",
        "| `SelfAskWithSearchChain`           | Answer via planning + search     | 🔹 Medium        | ✅ Yes             | Web-enabled reasoning with multiple hops            |\n",
        "| `SQLDatabaseChain`                 | Natural language → SQL           | 🔹 Medium        | ✅ Yes             | Use LLMs to query tabular/SQL data                  |\n",
        "| `LCEL`                             | Declarative, composable pipeline | 🔹🔹🔹 Highest   | ✅ Yes             | You want clean functional-style LLM flow definition |\n",
        "\n",
        "---\n",
        "\n",
        "## 📊 Flow Diagram: **When to Use Which LangChain Chain**\n",
        "\n",
        "```plaintext\n",
        "                 ┌────────────────────┐\n",
        "                 │ What is your goal?│\n",
        "                 └─────────┬──────────┘\n",
        "                           │\n",
        "        ┌──────────────────┼───────────────────┐\n",
        "        ▼                                      ▼\n",
        "Simple Prompt/Response                Document Processing\n",
        "   (Single-step LLM)                  (Chunked or Long)\n",
        "        │                                      │\n",
        "        ▼                                      ▼\n",
        "  Use `LLMChain`                  ┌────────────┼────────────┐\n",
        "                                  ▼                         ▼\n",
        "                        Docs fit in prompt?       Docs too long?\n",
        "                              │                         │\n",
        "                         Yes ▼                         ▼ Yes\n",
        "                        Use `Stuff`             Use `MapReduce` or `Refine`\n",
        "\n",
        "        ┌──────────────────┐\n",
        "        │ Multi-step Logic │────────────┐\n",
        "        └───────┬──────────┘            │\n",
        "                ▼                       ▼\n",
        "     Use `SequentialChain`       Dynamic Routing Needed?\n",
        "                                       │\n",
        "                                  Yes ▼\n",
        "                            Use `RouterChain`\n",
        "\n",
        "        ┌──────────────────┐\n",
        "        │ Stateful Dialogue│\n",
        "        └───────┬──────────┘\n",
        "                ▼\n",
        "         Use `ConversationalChain`\n",
        "\n",
        "        ┌──────────────────┐\n",
        "        │ External Knowledge? (search/sql)│\n",
        "        └───────┬──────────┘\n",
        "                ▼\n",
        "  Use `SelfAskWithSearch` or `SQLDatabaseChain`\n",
        "\n",
        "        ┌────────────────────────────┐\n",
        "        │ Want complete I/O control? │\n",
        "        └───────┬────────────────────┘\n",
        "                ▼\n",
        "        Use `TransformChain` or `LCEL`\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Recommendations by Use Case\n",
        "\n",
        "| Use Case                     | Recommended Chain(s)                              |\n",
        "| ---------------------------- | ------------------------------------------------- |\n",
        "| Simple Prompt Completion     | `LLMChain`, `LCEL`                                |\n",
        "| Multi-step Reasoning Flow    | `SequentialChain`, `TransformChain`, `LCEL`       |\n",
        "| Long Doc Summarization       | `MapReduceDocumentsChain`, `RefineDocumentsChain` |\n",
        "| Domain-based Prompt Routing  | `RouterChain`, `MultiPromptChain`                 |\n",
        "| Conversational Agents        | `ConversationChain` with `ConversationMemory`     |\n",
        "| Data Lookup or Search        | `SelfAskWithSearchChain`, `SQLDatabaseChain`      |\n",
        "| High Modularity / Debuggable | `LCEL`, `TransformChain`, `SequentialChain`       |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7ZMOpJcqXJDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vBb0L9DcogAz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}